# Part-III: Statistics with R {-}
```{r echo=FALSE, message=FALSE}
library(tidyverse)
```


# Descriptive statistics
Exploratory Data Analysis or often abbreviated as EDA, is mostly the first and foremost step before carrying out any data analytics task, is used to analyze and investigate data sets and summarize their main characteristics, often employing data visualization methods.  EDA is primarily used to see what data can reveal beyond the formal modeling or hypothesis testing task and provides a provides a better understanding of data set variables and the relationships between them. It can also help determine if the statistical techniques you are considering for data analysis are appropriate. Originally developed by American mathematician John Tukey in the 1960s, EDA techniques continue to be a widely used method in the data discovery process today.

## Using base R
Base R provides us with two functions used ato ascertain structure and summary statistics of a data frame.  First is `str` short for __structure__ (and not to be confused with **str**ing) which as its full name suggests gives us structure of the data.  Its usage is simple

```{r}
str(iris)
```

As can be seen it gives us number of variables (columns) as well as observations (rows) available in the given data.  It thereafter presents us names of all the columns/variables in the data along with their types.  That's not all.  It also prints few first values in all of the columns.  For `factor` columns it also gives us available levels in those factor variables.

Another function from base R is `summary` which can be used to generate some summary statistics from the given data frame.  Let's see what we can get from this function.

```{r}
summary(iris)
```

We can see that it nicely gives us five-point summary for all `numeric` variables and count of all values present in `factor` variables. Apart from the five point summary i.e. (1) minimum, (2) 1st quartile, (3) Median, (4) third quartile and (5) maximum; we also get mean (arithmetic) of all numeric variables.

Before moving forward, we can discuss again `table()` function here which is used to genrate counts of factor/character variable(s) in base R.

```{r}
with(iris, table(Species))
```
## Dplyr functions

For calculating other statistics we can use `dplyr::summarise` in combination with `across`.  For Example to calculate `mean`, `sd`, `variance` for all numeric variables of say `iris` data, we can do-

```{r}
library(dplyr)
iris %>%
  summarise(across(where(is.numeric),
                   .fns = list(
                     Mean = ~ mean(.),
                     SD = ~ sd(.),
                     Var = ~ var(.)
                   )))
```

Before trying to understand the output let's learn to use `dplyr::across`.  Actually `across` is used inside dplyr verbs mostly with `mutate` or `summarise` through which we can mutate/summarise multiple variables (columns) simultaneously.  So, at least two arguments are needed; first variable names which can be provided through a type checking variable, str detecting function, etc.; and second argument either a function name or a list of functions together.  So in above example we have summarised all numeric columns (see first argument is a function `is.numeric` which only operates on column names) and second argument is a list of three functions in lambda style notation.  In our example we are having 4 numeric columns and three aggregating functions, so 12 columns we are getting in output.  

We can further reshape/transform the data using `tidyr::pivot_longer`.  See

```{r}
library(tidyr)
iris %>%
  summarise(across(where(is.numeric),
                   .fns = list(
                     Mean = ~ mean(.),
                     SD = ~ sd(.),
                     Var = ~ var(.)
                   ))) %>%
  pivot_longer(everything(),
               names_sep = "_",
               names_to = c(".value", "Function"))
```

```{r}
iris %>%
  summarise(across(where(is.numeric),
                   .fns = list(
                     Mean = ~ mean(.),
                     SD = ~ sd(.),
                     Var = ~ var(.)
                   ))) %>%
  pivot_longer(everything(),
               names_sep = "_",
               names_to = c("Variable", ".value"))
```

Let us also discuss one more data summary statistics function of `dplyr` that is `glimpse`.  It is basically a pipe friendly version of `str()`.  See

```{r}
iris %>% 
  glimpse()
```
To calculate counts of factor variable (as generated by `table` in base R), we can use `dplyr::count` a pipe friendly function.

```{r}
iris %>% 
  count(Species)
```
We can generate counts of multiple combinations of variables
```{r}
ggplot2::diamonds %>% 
  count(cut, color, name = "count")
```


## Using another package `psych`
There are indeed some beautiful packages in R, which creates beautiful EDA summaries for us without much ado.  Package `psych` is one of these.

```{r}
library(psych)
describe(USArrests)
```

Note that output is in `data.frame` format ready to use.  Another function in `psych` is `describeBy` which creates grouped summaries.
```{r}
describeBy(ggplot2::diamonds, group = "cut")
```

There is one more function `describeData` is this package which also results in first as well as last four (default) values.

```{r}
describeData(ggplot2::diamonds)
```

## Using `skimr`

Package `skimr` generates beautiful data EDA summary reports which can be customised as per one's taste.  Full descriptions of this package may be seen [here](https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html).  For basic purposes we can use function `skim` from this package to get data EDA summary reports.

```
library(skimr)
skim(iris)
```
```{r skimrr, fig.show='hold', out.width='50%', echo=FALSE}
knitr::include_graphics('images/skmi1.png')
```

## Viewing relationships between different variables

We can use package `PerformanceAnalytics` to generate and view relationships between different variables in the data.  For this purpose function `PerformanceAnalytics::chart.Correlation()` may be used as shown below.

```{r warning=FALSE, fig.show='hold', fig.align='center', fig.cap="Viewing relationships with PerformanceAnalytics"}
suppressMessages(library(PerformanceAnalytics))

USArrests %>% 
  select(where(is.numeric)) %>% 
  PerformanceAnalytics::chart.Correlation()
```
As can be seen that it generates visualization of a Correlation Matrix of the numeric variables in the given data.  


There is one more package `GGally` which also creates beautiful charts for viewing relationships.  There are two functions in this package which are particularly useful.

1. The `ggpairs()` function of the GGally package allows to build a great scatterplot matrix.  Scatterplots of each pair of numeric variable are drawn on the left part of the figure. Pearson correlation is displayed on the right. Variable distribution is available on the diagonal.

2. The `ggcorr()` function allows to visualize the correlation of each pair of variable as a square. Note that the method argument allows to pick the correlation type you desire.

See the following example-
```{r two-corr, fig.show='hold', out.width="50%", warning=FALSE, fig.cap="Scatterplot Matrix (Left) and Correlation plot (Right) produced in GGally", fig.align='center'}
suppressMessages(library(GGally))
USArrests %>% 
  select_if(is.numeric) %>% 
  ggcorr(label = TRUE)

USArrests %>% 
  select_if(is.numeric) %>%
  ggpairs()

```


# Probability in R
We will keep short here.  Instead of learning all the concepts of probability, we will see how to calculate probability, densities, quantiles for nearly any type of distribution.  R's powerhorse has four types of functions for each of the distributions associated called `pqdr` functions.  Actually all these are prefixes.  Consider a probability function $P(X=x) = p$ for a variable $x$ and $p$ be the associated probability.  

| Distribution                   | P |  Q | D | R  |
| ------------------------------ | --------- | ------ | ----- | -----|
| Beta                           | pbeta     | qbeta | dbeta | rbeta |
| Binomial                       | pbinom    | qbinom | dbinom | rbinom |
| Cauchy                         | pcauchy   | qcauchy | dcauchy | rcauchy |
| Chi-Square                     | pchisq    | qchisq | dchisq | rchisq |
| Exponential                    | pexp      | qexp | dexp | rexp |
| F                              | pf        | qf | df | rf |
| Gamma                          | pgamma    | qgamma | dgamma | rgamma |
| Geometric                      | pgeom     | qgeom | dgeom | rgeom |
| Hypergeometric                 | phyper    | qhyper | dhyper | rhyper |
| Logistic                       | plogis    | qlogis | dlogis | rlogis |
| Log Normal                     | plnorm    | qlnorm | dlnorm | rlnorm |
| Negative Binomial              | pnbinom   | qnbinom | dnbinom | rnbinom |
| Normal                         | pnorm     | qnorm | dnorm | rnorm |
| Poisson                        | ppois     | qpois | dpois | rpois |
| Student t                      | pt        | qt | dt | rt |
| Studentized Range              | ptukey    | qtukey | dtukey | rtukey |
| Uniform                        | punif     | qunif | dunif | runif |
| Weibull                        | pweibull  | qweibull | dweibull | rweibull |
| Wilcoxon Rank Sum Statistic    | pwilcox   | qwilcox | dwilcox | rwilcox |
| Wilcoxon Signed Rank Statistic | psignrank | qsignrank | dsignrank | rsignrank |

All these functions are vectorised. Let us explore these one by one.


## `p*()` set of functions
These set of functions give the cumulative **p**robability distribution of that probability function.  

Example-1.  What is the probability of a number being less than or equal to `25` in `Normal` distribution with `mean = 50` and `sd = 10`.

```{r}
pnorm(25, mean = 50, sd = 10)
```

On the contrary, the probability of a number being greater than or equal to 25 in the above distribution is-
```{r}
# Either deduct probability from 1 
1 - pnorm(25, mean = 50, sd = 10)
# Or provide FALSE to lower.tail argument
pnorm(25, mean = 50, sd = 10, lower.tail = FALSE)
```

Example-2: What is the probability of one or more heads out of two tosses of a fair coin (binomial distribution with `p = 0.5`).

```{r}
pbinom(1, size = 2, p = 0.5)
```


## `q*()` set of functions
These set of functions, give **q**uantile which is the inverse of cumulative probability function. So if $f$ is cdf (cumulative distribution function) of a given probability distribution then $F$ the quantile is inverse of `f` i.e. $F = f^{-1}$.  These are related by

\begin{equation} 
p = f(x)
(\#eq:s1)
\end{equation} 

\begin{equation} 
x = F(x) = f^{-1}(x)
(\#eq:s2)
\end{equation} 

Example- In the above same normal distribution (`mean = 50` and `sd = 10`) What is number below which 90% of population will be distributed.

```{r}
qnorm(0.9, mean = 50, sd = 10)
```

Similar to `cdf` here we may use `lower.tail` argument to find the number above which a population percent is distributed.
```{r}
qnorm(0.9, mean = 50, sd = 10, lower.tail = FALSE)
```

## `d*()` set of functions
We saw that `p` group denotes `cdf`, `q` group denotes `inverse cdf`, but `d` group actually denotes probability **d**ensity function of a given distribution.  Simply stating, this returns the height of probability distribution function for a given x value.

So what is expected probability of drawing exactly 2 heads out of two tosses of a single fair coin (i.e. from a binomial distribution with probability `p = 0.5`).

```{r}
dbinom(2, 2, prob = 0.5)
```

## `r*()` set of functions
These set of functions are used to generate **r**andom numbers from a Statistical distribution.  So to generate `10` random numbers from Normal distribution with `mean = 50` and `sd = 10`, we can use `rnorm`.

```{r}
rnorm(10, mean = 50, sd = 10)
```

We can actually check this using histogram.
```{r fig.align='center', fig.show='hold', fig.cap="Histogram of Random numbers generated out of Normal distribution", out.width="75%"}
set.seed(1234)
hist(rnorm(10000, 50, 10), breaks = 50)
```


