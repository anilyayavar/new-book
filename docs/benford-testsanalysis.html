<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 38 Benford Tests/Analysis | R for Audit Analytics</title>
<meta name="author" content="Anil Goyal">
<meta name="description" content="38.1 Introduction and Historical context Benford’s Law stands out as an analysis method for both visualizing and evaluating numerical data, especially when focused on detecting fraud. It’s really...">
<meta name="generator" content="bookdown 0.40 with bs4_book()">
<meta property="og:title" content="Chapter 38 Benford Tests/Analysis | R for Audit Analytics">
<meta property="og:type" content="book">
<meta property="og:url" content="https://anilyayavar.github.io/new-book/benford-testsanalysis.html">
<meta property="og:image" content="https://anilyayavar.github.io/new-book/images/cover.jpg">
<meta property="og:description" content="38.1 Introduction and Historical context Benford’s Law stands out as an analysis method for both visualizing and evaluating numerical data, especially when focused on detecting fraud. It’s really...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 38 Benford Tests/Analysis | R for Audit Analytics">
<meta name="twitter:description" content="38.1 Introduction and Historical context Benford’s Law stands out as an analysis method for both visualizing and evaluating numerical data, especially when focused on detecting fraud. It’s really...">
<meta name="twitter:image" content="https://anilyayavar.github.io/new-book/images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.7.0/transition.js"></script><script src="libs/bs3compat-0.7.0/tabs.js"></script><script src="libs/bs3compat-0.7.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">R for Audit Analytics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome to R for Audit Analytics</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="about-author.html">About author</a></li>
<li><a class="" href="gearing-up.html">Gearing up</a></li>
<li><a class="" href="part-i-basic-r-programming-concepts.html">Part-I: Basic R Programming Concepts</a></li>
<li><a class="" href="r-programming-language.html"><span class="header-section-number">1</span> R Programming Language</a></li>
<li><a class="" href="subset.html"><span class="header-section-number">2</span> Subsetting R objects or accesing specific elements</a></li>
<li><a class="" href="func.html"><span class="header-section-number">3</span> Functions and operations in R</a></li>
<li><a class="" href="existing-and-useful-functions-in-base-r.html"><span class="header-section-number">4</span> Existing and useful functions in base R</a></li>
<li><a class="" href="pipes-in-r.html"><span class="header-section-number">5</span> Pipes in R</a></li>
<li><a class="" href="control-statements.html"><span class="header-section-number">6</span> Control statements</a></li>
<li><a class="" href="functional-programming.html"><span class="header-section-number">7</span> Functional Programming</a></li>
<li><a class="" href="file.html"><span class="header-section-number">8</span> File handling operations in R</a></li>
<li><a class="" href="read.html"><span class="header-section-number">9</span> Getting data in and out of R</a></li>
<li><a class="" href="data-cleaning-in-r.html"><span class="header-section-number">10</span> Data Cleaning in R</a></li>
<li><a class="" href="merging-large-number-of-similar-datasets-into-one.html"><span class="header-section-number">11</span> Merging large number of similar datasets into one</a></li>
<li><a class="" href="part-ii-exploratory-data-analysis.html">Part-II: Exploratory Data Analysis</a></li>
<li><a class="" href="visualisations-in-base-r.html"><span class="header-section-number">12</span> Visualisations in Base R</a></li>
<li><a class="" href="visualising-data-with-ggplot2.html"><span class="header-section-number">13</span> Visualising data with ggplot2</a></li>
<li><a class="" href="data-transformation-in-dplyr.html"><span class="header-section-number">14</span> Data Transformation in dplyr</a></li>
<li><a class="" href="combining-tablestabular-data.html"><span class="header-section-number">15</span> Combining Tables/tabular data</a></li>
<li><a class="" href="data-wrangling-in-tidyr.html"><span class="header-section-number">16</span> Data Wrangling in tidyr</a></li>
<li><a class="" href="generating-descriptive-statistics.html"><span class="header-section-number">17</span> Generating Descriptive statistics</a></li>
<li><a class="" href="part-iii-probability-and-sampling-in-r.html">Part-III: Probability and Sampling in R</a></li>
<li><a class="" href="probability-in-r.html"><span class="header-section-number">18</span> Probability in R</a></li>
<li><a class="" href="random-sampling-in-r.html"><span class="header-section-number">19</span> Random sampling in R</a></li>
<li><a class="" href="part-iv-machine-learning-in-r.html">Part-IV: Machine Learning in R</a></li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">20</span> Linear Regression</a></li>
<li><a class="" href="principal-component-analysis-in-r.html"><span class="header-section-number">21</span> Principal Component Analysis in R</a></li>
<li><a class="" href="clustering-in-r-using-kmeans-algorithm.html"><span class="header-section-number">22</span> Clustering in R (Using Kmeans algorithm)</a></li>
<li><a class="" href="association-rule-mining-in-r-apriori.html"><span class="header-section-number">23</span> Association Rule Mining in R (Apriori)</a></li>
<li><a class="" href="part-v-time-series-analysis.html">Part-V: Time Series Analysis</a></li>
<li><a class="" href="dates-and-times.html"><span class="header-section-number">24</span> Dates and Times</a></li>
<li><a class="" href="time-series-analysis.html"><span class="header-section-number">25</span> Time Series Analysis</a></li>
<li><a class="" href="part-vi-network-analytics.html">Part VI: Network Analytics</a></li>
<li><a class="" href="network-analyticsgraph-theory-in-r.html"><span class="header-section-number">26</span> Network Analytics/Graph theory in R</a></li>
<li><a class="" href="applying-network-analysis-in-auditfraud-detection.html"><span class="header-section-number">27</span> Applying network analysis in audit/fraud detection</a></li>
<li><a class="" href="part-vii-text-analytics-in-r.html">Part-VII: Text Analytics in R</a></li>
<li><a class="" href="string-manipulation-in-stringr.html"><span class="header-section-number">28</span> String manipulation in stringr</a></li>
<li><a class="" href="regex---a-quick-introduction.html"><span class="header-section-number">29</span> Regex - A quick introduction</a></li>
<li><a class="" href="regex-in-human-readble-format-using-rebus.html"><span class="header-section-number">30</span> Regex in human readble format using rebus</a></li>
<li><a class="" href="text-analytics-in-r.html"><span class="header-section-number">31</span> Text Analytics in R</a></li>
<li><a class="" href="sentiment-analysis.html"><span class="header-section-number">32</span> Sentiment Analysis</a></li>
<li><a class="" href="visualising-text-analytics-through-wordcloud-etc..html"><span class="header-section-number">33</span> Visualising Text analytics through Wordcloud, etc.</a></li>
<li><a class="" href="finding-string-similarity.html"><span class="header-section-number">34</span> Finding string similarity</a></li>
<li><a class="" href="part-viii-geo-computation-in-r.html">Part-VIII: Geo computation in R</a></li>
<li><a class="" href="maps-in-r.html"><span class="header-section-number">35</span> Maps in R</a></li>
<li><a class="" href="geo-coding-in-r.html"><span class="header-section-number">36</span> Geo-Coding in R</a></li>
<li><a class="" href="reverse-geo-coding.html"><span class="header-section-number">37</span> Reverse geo-coding</a></li>
<li><a class="" href="part-ix-identifying-anamolous-observations-for-audit.html">Part-IX: Identifying anamolous observations for audit</a></li>
<li><a class="active" href="benford-testsanalysis.html"><span class="header-section-number">38</span> Benford Tests/Analysis</a></li>
<li><a class="" href="anomaly-detection.html"><span class="header-section-number">39</span> Anomaly Detection</a></li>
<li><a class="" href="finding-anamolous-outliers.html"><span class="header-section-number">40</span> Finding Anamolous Outliers</a></li>
<li><a class="" href="dup.html"><span class="header-section-number">41</span> Duplicate Detection</a></li>
<li><a class="" href="detecting-gaps-in-sequences.html"><span class="header-section-number">42</span> Detecting gaps in sequences</a></li>
<li><a class="" href="data-envelopment-analysis.html"><span class="header-section-number">43</span> Data Envelopment Analysis</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="colors-in-r.html"><span class="header-section-number">A</span> Colors in R</a></li>
<li><a class="" href="various-datasets-in-base-r-used-in-this-book.html"><span class="header-section-number">B</span> Various Datasets, in base R, used in this book</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="benford-testsanalysis" class="section level1" number="38">
<h1>
<span class="header-section-number">38</span> Benford Tests/Analysis<a class="anchor" aria-label="anchor" href="#benford-testsanalysis"><i class="fas fa-link"></i></a>
</h1>
<div id="introduction-and-historical-context" class="section level2" number="38.1">
<h2>
<span class="header-section-number">38.1</span> Introduction and Historical context<a class="anchor" aria-label="anchor" href="#introduction-and-historical-context"><i class="fas fa-link"></i></a>
</h2>
<p>Benford’s Law stands out as an analysis method for both visualizing and evaluating numerical data, especially when focused on detecting fraud. It’s really handy for catching potential trickery, especially in spotting fraud. This rule tells us how often different digits (like 1, 2, 3, etc.) should show up as the first number in lots of real-world data. This law describes the frequency distribution of the first digit, from left hand side, in many real-life data sets which counter-intuitively is not uniform, and is shown in Figure <a href="benford-testsanalysis.html#fig:benlaw">38.2</a>. Significant differences from the anticipated occurrence rates could signal that the data is questionable and might have been altered. For instance, eligibility for government assistance often hinges on meeting specific criteria, like having an income below a certain level. As a result, data might be manipulated to meet these criteria. This kind of manipulation is precisely what Benford’s Law can detect since fabricated numbers won’t align with the expected frequency pattern outlined by the law.</p>
<p>The Law is named after physicist <strong>Frank Benford</strong>, who worked on the theory in 1938 and as a result a paper titled <strong>The Law of Anomalous Numbers</strong> was published.<span class="citation"><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Frank Benford, &lt;span&gt;“The Law of Anomalous Numbers,”&lt;/span&gt; &lt;em&gt;Proceedings of the American Philosophical Society&lt;/em&gt; 78, no. 4 (1938): 551–72, &lt;a href="http://www.jstor.org/stable/984802"&gt;http://www.jstor.org/stable/984802&lt;/a&gt;.&lt;/p&gt;'><sup>38</sup></a></span>. However, its discovery is associated more than five decades earlier when astronomer <strong>Simon Newcomb</strong> observed that initial pages of log tables booklet were more worn out than later pages and published a two page article titled <strong>Note on the Frequency of Use of the Different Digits in Natural Numbers</strong> in 1881.<span class="citation"><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Simon Newcomb, &lt;span&gt;“Note on the Frequency of Use of the Different Digits in Natural Numbers,”&lt;/span&gt; &lt;em&gt;American Journal of Mathematics&lt;/em&gt; 4, no. 1 (1881): 39–40, &lt;a href="http://www.jstor.org/stable/2369148"&gt;http://www.jstor.org/stable/2369148&lt;/a&gt;.&lt;/p&gt;'><sup>39</sup></a></span></p>
<p>More researchers continued to work on Benford’s law and its extensions. However, it took several decades to find a truly practical application. It was in last decade of twentieth Century, when Dr. Mark J. Nigrini, an accounting Professor, used the law for fraud detection/anaytics and came up with a practical fraud application. He reviewed multiple data sources like sales figures, insurance claim costs, and expense reimbursement claims and did studies on detecting overstatements and understatement of financial figures. His research confirmed the law’s proven usefulness to fraud examiners and auditors in accounting engagements.</p>
<p>His theory is that - <em>If somebody tries to falsify, say, their tax return then invariably they will have to invent some data. When trying to do this, the tendency is for people to use too many numbers starting with digits in the mid range, 5,6,7 and thus not enough numbers starting with 1.</em></p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:benpics"></span>
<img src="images/frank_benford.jpg" alt="(L to R) Frank Benford, Simon Newcomb, and Mark Nigrini (Source: Wiki)" width="32%" height="32%"><img src="images/Simon.jpg" alt="(L to R) Frank Benford, Simon Newcomb, and Mark Nigrini (Source: Wiki)" width="32%" height="32%"><img src="images/nigrini.jpg" alt="(L to R) Frank Benford, Simon Newcomb, and Mark Nigrini (Source: Wiki)" width="32%" height="32%"><p class="caption">
Figure 38.1: (L to R) Frank Benford, Simon Newcomb, and Mark Nigrini (Source: Wiki)
</p>
</div>
</div>
<div id="benfords-law-properties-and-extensions" class="section level2" number="38.2">
<h2>
<span class="header-section-number">38.2</span> Benford’s Law, properties and extensions<a class="anchor" aria-label="anchor" href="#benfords-law-properties-and-extensions"><i class="fas fa-link"></i></a>
</h2>
<div id="law-of-first-digit" class="section level3" number="38.2.1">
<h3>
<span class="header-section-number">38.2.1</span> Law of first digit<a class="anchor" aria-label="anchor" href="#law-of-first-digit"><i class="fas fa-link"></i></a>
</h3>
<p>When considering the likelihood of any digit being in the first position (from the left), our initial assumption might be a simple <em>one out of nine</em> scenario, following a uniform distribution. However, this notion was challenged by Canadian-American astronomer <strong>Simon Newcomb</strong> in 1881, who noticed unusual wear patterns in logarithmic tables. While casually flipping through a logarithmic tables booklet, he discerned a curious pattern— the initial pages exhibited more wear and tear than their later counterparts.</p>
<p>Subsequently, <strong>Frank Benford</strong> conducted a comprehensive analysis of 20 diverse datasets encompassing river sizes, chemical compound weights, population data, and more. His findings revealed a successive diminishment in probability from digit 1 to 9. In essence, the probability of digit 1 occurring in the initial position is the highest, while that of digit 9 is the lowest.</p>
<p>Mathematically, <em>Benford’s Law</em> or <em>Law of first digits</em> states that the probability of any digit in first place should follow the equation <a href="benford-testsanalysis.html#eq:ben1">(38.1)</a>.</p>
<span class="math display" id="eq:ben1">\[\begin{equation}
P(d_i) = \log_{10}\left(1 + \frac{1}{d}\right)
\tag{38.1}
\end{equation}\]</span>
<ul>
<li>Where <span class="math inline">\(d_i\)</span> ranges from <span class="math inline">\(1\)</span> to <span class="math inline">\(9\)</span>.</li>
</ul>
<p>The probabilities when plotted will generate plot as depicted in Figure <a href="benford-testsanalysis.html#fig:benlaw">38.2</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:benlaw"></span>
<img src="DauR_files/figure-html/benlaw-1.png" alt="Diminishing Probabilities of First Digits - Benford Law" width="672" height="32%"><p class="caption">
Figure 38.2: Diminishing Probabilities of First Digits - Benford Law
</p>
</div>
<p>To test the proposed law, Benford analysed 20 different data-sets and he observed that nearly all follow the distribution mentioned in equation <a href="benford-testsanalysis.html#eq:ben1">(38.1)</a>.</p>
<p>Let us also try to see whether the law holds by anlaysing six different datasets, which are included in R’s package called <code>benford.analysis</code>. Though we will discuss about the package in detail later in section <a href="benford-testsanalysis.html#pracben">38.5</a>. The six datasets are mentioned in Table <a href="benford-testsanalysis.html#tab:sixben">38.1</a>.</p>
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:sixben">Table 38.1: </span><span id="tab:sixben">Table 38.2: </span>List of six datasets for testing Benford Analysis
</caption>
<thead><tr>
<th style="text-align:center;">
Item
</th>
<th style="text-align:center;">
Title
</th>
<th style="text-align:center;">
Column
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:center;">
census.2000_2010
</td>
<td style="text-align:center;">
Population data - US - 2000 and 2010
</td>
<td style="text-align:center;">
pop.2000
</td>
</tr>
<tr>
<td style="text-align:center;">
census.2009
</td>
<td style="text-align:center;">
Population data of Towns and Cities of the US - 2009
</td>
<td style="text-align:center;">
pop.2009
</td>
</tr>
<tr>
<td style="text-align:center;">
corporate.payment
</td>
<td style="text-align:center;">
Corporate payments of a West Coast utility company - 2010
</td>
<td style="text-align:center;">
Amount
</td>
</tr>
<tr>
<td style="text-align:center;">
lakes.perimeter
</td>
<td style="text-align:center;">
Perimeter of lakes arround the world
</td>
<td style="text-align:center;">
perimeter.km
</td>
</tr>
<tr>
<td style="text-align:center;">
sino.forest
</td>
<td style="text-align:center;">
Financial Statemens of Sino Forest Corporation’s 2010 Report
</td>
<td style="text-align:center;">
value
</td>
</tr>
<tr>
<td style="text-align:center;">
taxable.incomes.1978
</td>
<td style="text-align:center;">
Taxable Income 1978
</td>
<td style="text-align:center;">
taxIncomes
</td>
</tr>
</tbody>
</table></div>
<p>The results of Benford’s law of first digit on these six datasets are calculated and have been mentioned in Table <a href="benford-testsanalysis.html#tab:tab1">38.3</a>. It can be seen that actual frequencies of first digits, in these six datasets follow Benford’s Law. We can even plot the actual frequencies to inspect results visually. Actual Frequencies in these six datasets are plotted in <a href="benford-testsanalysis.html#fig:benplots">38.3</a> and it may be seen that these follow Benford’s Law largely.</p>
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:tab1">Table 38.3: </span><span id="tab:tab1">Table 38.4: </span>Results of First order tests on six datasets
</caption>
<thead><tr>
<th style="text-align:right;">
digits
</th>
<th style="text-align:right;">
Benford
</th>
<th style="text-align:right;">
Census 2000_2010
</th>
<th style="text-align:right;">
Census 2009
</th>
<th style="text-align:right;">
Corporate Payment
</th>
<th style="text-align:right;">
Lakes Perimeter
</th>
<th style="text-align:right;">
Sino Forest
</th>
<th style="text-align:right;">
Taxable Incomes 1978
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.3010300
</td>
<td style="text-align:right;">
0.3092126
</td>
<td style="text-align:right;">
0.2941207
</td>
<td style="text-align:right;">
0.3175548
</td>
<td style="text-align:right;">
0.1508888
</td>
<td style="text-align:right;">
0.2992228
</td>
<td style="text-align:right;">
0.3278721
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0.1760913
</td>
<td style="text-align:right;">
0.1797896
</td>
<td style="text-align:right;">
0.1814547
</td>
<td style="text-align:right;">
0.1611007
</td>
<td style="text-align:right;">
0.0687752
</td>
<td style="text-align:right;">
0.1606218
</td>
<td style="text-align:right;">
0.2140886
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0.1249387
</td>
<td style="text-align:right;">
0.1271916
</td>
<td style="text-align:right;">
0.1200472
</td>
<td style="text-align:right;">
0.1101452
</td>
<td style="text-align:right;">
0.2170936
</td>
<td style="text-align:right;">
0.1256477
</td>
<td style="text-align:right;">
0.1235673
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0.0969100
</td>
<td style="text-align:right;">
0.0975454
</td>
<td style="text-align:right;">
0.0946743
</td>
<td style="text-align:right;">
0.0828655
</td>
<td style="text-align:right;">
0.1818372
</td>
<td style="text-align:right;">
0.0906736
</td>
<td style="text-align:right;">
0.0895397
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.0791812
</td>
<td style="text-align:right;">
0.0656678
</td>
<td style="text-align:right;">
0.0799118
</td>
<td style="text-align:right;">
0.1016301
</td>
<td style="text-align:right;">
0.1309577
</td>
<td style="text-align:right;">
0.0829016
</td>
<td style="text-align:right;">
0.0722473
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
0.0669468
</td>
<td style="text-align:right;">
0.0656678
</td>
<td style="text-align:right;">
0.0702240
</td>
<td style="text-align:right;">
0.0602811
</td>
<td style="text-align:right;">
0.0930143
</td>
<td style="text-align:right;">
0.0699482
</td>
<td style="text-align:right;">
0.0521491
</td>
</tr>
<tr>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0.0579919
</td>
<td style="text-align:right;">
0.0541919
</td>
<td style="text-align:right;">
0.0597673
</td>
<td style="text-align:right;">
0.0498209
</td>
<td style="text-align:right;">
0.0682885
</td>
<td style="text-align:right;">
0.0518135
</td>
<td style="text-align:right;">
0.0411117
</td>
</tr>
<tr>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
0.0511525
</td>
<td style="text-align:right;">
0.0548295
</td>
<td style="text-align:right;">
0.0534625
</td>
<td style="text-align:right;">
0.0503666
</td>
<td style="text-align:right;">
0.0502118
</td>
<td style="text-align:right;">
0.0699482
</td>
<td style="text-align:right;">
0.0393606
</td>
</tr>
<tr>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.0457575
</td>
<td style="text-align:right;">
0.0459037
</td>
<td style="text-align:right;">
0.0463376
</td>
<td style="text-align:right;">
0.0662351
</td>
<td style="text-align:right;">
0.0389329
</td>
<td style="text-align:right;">
0.0492228
</td>
<td style="text-align:right;">
0.0400637
</td>
</tr>
</tbody>
</table></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:benplots"></span>
<img src="DauR_files/figure-html/benplots-1.png" alt="Distribution of first digit frequencies in six datasets" width="672"><p class="caption">
Figure 38.3: Distribution of first digit frequencies in six datasets
</p>
</div>
</div>
<div id="scale-invariance" class="section level3" number="38.2.2">
<h3>
<span class="header-section-number">38.2.2</span> Scale Invariance<a class="anchor" aria-label="anchor" href="#scale-invariance"><i class="fas fa-link"></i></a>
</h3>
<p>Later in 1961, <strong>Roger Pinkham</strong> showed that law is invariant to scaling.<span class="citation"><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Roger S. Pinkham, &lt;span&gt;“&lt;span class="nocase"&gt;On the Distribution of First Significant Digits&lt;/span&gt;,”&lt;/span&gt; &lt;em&gt;The Annals of Mathematical Statistics&lt;/em&gt; 32, no. 4 (1961): 1223–30, &lt;a href="https://doi.org/10.1214/aoms/1177704862"&gt;https://doi.org/10.1214/aoms/1177704862&lt;/a&gt;.&lt;/p&gt;'><sup>40</sup></a></span> By <em>Scale Invariance</em>, he actually showed that the law is invariant to measurements units. In other words, the law still holds if we convert units from one unit to another. For example, if price or amount figures are measured either in USD or in INR, length is measured either in KMs or Miles, the digit frequencies still follow the Benford’s Law.</p>
<p>Let us check this on one of the six datasets mentioned above, namely <code>census.2009</code>. This data-set contains the figures of population of towns and cities of the United States, as of July of 2009. We can see that first digit frequencies follow Benford’s Law/Pinkham’s Corollary in Figure <a href="benford-testsanalysis.html#fig:census">38.4</a>. Left plot shows frequencies on original data whereas right plot shows these on randonly scaled data.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:census"></span>
<img src="DauR_files/figure-html/census-1.png" alt="First Digit Analysis on US Census 2009 data (Left) and Scaled Data (Right)" width="45%"><img src="DauR_files/figure-html/census-2.png" alt="First Digit Analysis on US Census 2009 data (Left) and Scaled Data (Right)" width="45%"><p class="caption">
Figure 38.4: First Digit Analysis on US Census 2009 data (Left) and Scaled Data (Right)
</p>
</div>
<p>Figure <a href="benford-testsanalysis.html#fig:census">38.4</a> (Left) shows that the law holds for the data. Let us also test the Pinkham’s corollary on the aforesaid data. For this let’s multiply all the figures of population by a random positive number. Through figure <a href="benford-testsanalysis.html#fig:census">38.4</a> (Right) it is clear that law still holds after scaling.</p>
</div>
<div id="first-two-digits" class="section level3" number="38.2.3">
<h3>
<span class="header-section-number">38.2.3</span> First two digits<a class="anchor" aria-label="anchor" href="#first-two-digits"><i class="fas fa-link"></i></a>
</h3>
<p>Nigrini’s contributions gained widespread recognition among scholars and practitioners, highlighting the applicability of Benford’s Law as a valuable forensic accounting and auditing tool across various datasets, particularly in the financial domain. <strong>Theodore P. Hill</strong> further<span class="citation"><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Theodore P. Hill, &lt;span&gt;“The Significant-Digit Phenomenon,”&lt;/span&gt; &lt;em&gt;The American Mathematical Monthly&lt;/em&gt; 102, no. 4 (1995): 322–27, &lt;a href="http://www.jstor.org/stable/2974952"&gt;http://www.jstor.org/stable/2974952&lt;/a&gt;.&lt;/p&gt;'><sup>41</sup></a></span> extended the scope of the law, demonstrating its validity beyond just the first digit to encompass other digits as well. Hill’s work expanded the utility of Benford’s Law, affirming its effectiveness in detecting irregularities and patterns not only in leading digits but throughout numerical sequences.</p>
<p>The formula for second significant digit can be written down in equation <a href="benford-testsanalysis.html#eq:ben2">(38.2)</a>.</p>
<span class="math display" id="eq:ben2">\[\begin{equation}
P(d_i) = \sum_{k = 1}^{9}\log_{10}\left(1 + \frac{1}{10k + d_i}\right)\;;\; d = 0,1,..9
\tag{38.2}
\end{equation}\]</span>
<ul>
<li>where <span class="math inline">\(k\)</span> represents first digit,</li>
<li>
<span class="math inline">\(d_i\)</span> represents second digit.</li>
</ul>
<p>The probabilities have been calculated, as depicted in Table <a href="benford-testsanalysis.html#tab:tab3">38.5</a>. Each cell depicts the probability of occurrence of any two digit, in left side, by first digit in rows and second digit in columns. We may also verify that, row totals thereby depicting probability of occurrence of first digit corresponds Benford’s Law of First Digit. For example, the probability of having first two digits as 10 will be highest at 4.14%.</p>
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:tab3">Table 38.5: </span><span id="tab:tab3">Table 38.6: </span>First and Second Digit distributions
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="10">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Second Significant Digit
</div>
</th>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
</tr>
<tr>
<th style="text-align:right;">
First Digit
</th>
<th style="text-align:right;">
0
</th>
<th style="text-align:right;">
1
</th>
<th style="text-align:right;">
2
</th>
<th style="text-align:right;">
3
</th>
<th style="text-align:right;">
4
</th>
<th style="text-align:right;">
5
</th>
<th style="text-align:right;">
6
</th>
<th style="text-align:right;">
7
</th>
<th style="text-align:right;">
8
</th>
<th style="text-align:right;">
9
</th>
<th style="text-align:right;">
First Digit Freq
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
4.14%
</td>
<td style="text-align:right;">
3.78%
</td>
<td style="text-align:right;">
3.48%
</td>
<td style="text-align:right;">
3.22%
</td>
<td style="text-align:right;">
3.00%
</td>
<td style="text-align:right;">
2.80%
</td>
<td style="text-align:right;">
2.63%
</td>
<td style="text-align:right;">
2.48%
</td>
<td style="text-align:right;">
2.35%
</td>
<td style="text-align:right;">
2.23%
</td>
<td style="text-align:right;">
30.10%
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
2.12%
</td>
<td style="text-align:right;">
2.02%
</td>
<td style="text-align:right;">
1.93%
</td>
<td style="text-align:right;">
1.85%
</td>
<td style="text-align:right;">
1.77%
</td>
<td style="text-align:right;">
1.70%
</td>
<td style="text-align:right;">
1.64%
</td>
<td style="text-align:right;">
1.58%
</td>
<td style="text-align:right;">
1.52%
</td>
<td style="text-align:right;">
1.47%
</td>
<td style="text-align:right;">
17.61%
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1.42%
</td>
<td style="text-align:right;">
1.38%
</td>
<td style="text-align:right;">
1.34%
</td>
<td style="text-align:right;">
1.30%
</td>
<td style="text-align:right;">
1.26%
</td>
<td style="text-align:right;">
1.22%
</td>
<td style="text-align:right;">
1.19%
</td>
<td style="text-align:right;">
1.16%
</td>
<td style="text-align:right;">
1.13%
</td>
<td style="text-align:right;">
1.10%
</td>
<td style="text-align:right;">
12.49%
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
1.07%
</td>
<td style="text-align:right;">
1.05%
</td>
<td style="text-align:right;">
1.02%
</td>
<td style="text-align:right;">
1.00%
</td>
<td style="text-align:right;">
0.98%
</td>
<td style="text-align:right;">
0.95%
</td>
<td style="text-align:right;">
0.93%
</td>
<td style="text-align:right;">
0.91%
</td>
<td style="text-align:right;">
0.90%
</td>
<td style="text-align:right;">
0.88%
</td>
<td style="text-align:right;">
9.69%
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.86%
</td>
<td style="text-align:right;">
0.84%
</td>
<td style="text-align:right;">
0.83%
</td>
<td style="text-align:right;">
0.81%
</td>
<td style="text-align:right;">
0.80%
</td>
<td style="text-align:right;">
0.78%
</td>
<td style="text-align:right;">
0.77%
</td>
<td style="text-align:right;">
0.76%
</td>
<td style="text-align:right;">
0.74%
</td>
<td style="text-align:right;">
0.73%
</td>
<td style="text-align:right;">
7.92%
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
0.72%
</td>
<td style="text-align:right;">
0.71%
</td>
<td style="text-align:right;">
0.69%
</td>
<td style="text-align:right;">
0.68%
</td>
<td style="text-align:right;">
0.67%
</td>
<td style="text-align:right;">
0.66%
</td>
<td style="text-align:right;">
0.65%
</td>
<td style="text-align:right;">
0.64%
</td>
<td style="text-align:right;">
0.63%
</td>
<td style="text-align:right;">
0.62%
</td>
<td style="text-align:right;">
6.69%
</td>
</tr>
<tr>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0.62%
</td>
<td style="text-align:right;">
0.61%
</td>
<td style="text-align:right;">
0.60%
</td>
<td style="text-align:right;">
0.59%
</td>
<td style="text-align:right;">
0.58%
</td>
<td style="text-align:right;">
0.58%
</td>
<td style="text-align:right;">
0.57%
</td>
<td style="text-align:right;">
0.56%
</td>
<td style="text-align:right;">
0.55%
</td>
<td style="text-align:right;">
0.55%
</td>
<td style="text-align:right;">
5.80%
</td>
</tr>
<tr>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
0.54%
</td>
<td style="text-align:right;">
0.53%
</td>
<td style="text-align:right;">
0.53%
</td>
<td style="text-align:right;">
0.52%
</td>
<td style="text-align:right;">
0.51%
</td>
<td style="text-align:right;">
0.51%
</td>
<td style="text-align:right;">
0.50%
</td>
<td style="text-align:right;">
0.50%
</td>
<td style="text-align:right;">
0.49%
</td>
<td style="text-align:right;">
0.49%
</td>
<td style="text-align:right;">
5.12%
</td>
</tr>
<tr>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.48%
</td>
<td style="text-align:right;">
0.47%
</td>
<td style="text-align:right;">
0.47%
</td>
<td style="text-align:right;">
0.46%
</td>
<td style="text-align:right;">
0.46%
</td>
<td style="text-align:right;">
0.45%
</td>
<td style="text-align:right;">
0.45%
</td>
<td style="text-align:right;">
0.45%
</td>
<td style="text-align:right;">
0.44%
</td>
<td style="text-align:right;">
0.44%
</td>
<td style="text-align:right;">
4.58%
</td>
</tr>
<tr>
<td style="text-align:right;">
Second Digit Freq
</td>
<td style="text-align:right;">
11.97%
</td>
<td style="text-align:right;">
11.39%
</td>
<td style="text-align:right;">
10.88%
</td>
<td style="text-align:right;">
10.43%
</td>
<td style="text-align:right;">
10.03%
</td>
<td style="text-align:right;">
9.67%
</td>
<td style="text-align:right;">
9.34%
</td>
<td style="text-align:right;">
9.04%
</td>
<td style="text-align:right;">
8.76%
</td>
<td style="text-align:right;">
8.50%
</td>
<td style="text-align:right;">
100.00%
</td>
</tr>
</tbody>
</table></div>
<p>The law of second digit combined with original Benford’s Law of first digit thus, gives us Law of first two digits. We can verify it in the example on <code>census.2009</code> data. The resultant plot as depicted in figure <a href="benford-testsanalysis.html#fig:ben2">38.5</a> shows us that the law of first two digits also holds.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ben2"></span>
<img src="DauR_files/figure-html/ben2-1.png" alt="Law holds for first two digits as well" width="672"><p class="caption">
Figure 38.5: Law holds for first two digits as well
</p>
</div>
</div>
<div id="second-order-test" class="section level3" number="38.2.4">
<h3>
<span class="header-section-number">38.2.4</span> Second order test<a class="anchor" aria-label="anchor" href="#second-order-test"><i class="fas fa-link"></i></a>
</h3>
<p><strong>Nigrini</strong> and <strong>Miller</strong>, in 2009,<span class="citation"><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Mark Nigrini and Steven Miller, &lt;span&gt;“Data Diagnostics Using Second-Order Tests of Benford’s Law,”&lt;/span&gt; &lt;em&gt;Auditing-a Journal of Practice and Theory - AUDITING-J PRACT THEOR&lt;/em&gt; 28 (November 2009), &lt;a href="https://doi.org/10.2308/aud.2009.28.2.305"&gt;https://doi.org/10.2308/aud.2009.28.2.305&lt;/a&gt;.&lt;/p&gt;'><sup>42</sup></a></span> introduced another advanced test based on Benford’s Law. The test states that:</p>
<blockquote>
<p>Let <span class="math inline">\(x_1\)</span>, …, <span class="math inline">\(x_N\)</span> be a data set comprising <span class="math inline">\(N\)</span> observations, and let <span class="math inline">\(y_1\)</span>, …, <span class="math inline">\(y_N\)</span> be the observations <span class="math inline">\(x_i\)</span>’s in ascending order. Then, for many natural data sets, and for large <span class="math inline">\(N\)</span>, the digits of the differences between adjacent observations <span class="math inline">\(y_{i+1} – y_i\)</span> is close to Benford’s Law. Large deviations from Benford’s Law indicate an anomaly that should be investigated.</p>
</blockquote>
<p>So, the steps may be listed as</p>
<ul>
<li>Sort data from smallest to largest</li>
<li>calculate <span class="math inline">\(N-1\)</span> differences of <span class="math inline">\(N\)</span> consecutive observations</li>
<li>Apply Benford’s law on these calculated new data.</li>
</ul>
<p>Nigrini showed that these digits are expected to closely follow the frequencies of Benford law. Using four different datasets he showed that this test can detect (i) anomalies occurring in data, (ii) whether the data has been rounded and (iii) use of fake data OR ‘statistically generated data’ in place of actual (transactional) data.</p>
</div>
<div id="summation-test" class="section level3" number="38.2.5">
<h3>
<span class="header-section-number">38.2.5</span> Summation Test<a class="anchor" aria-label="anchor" href="#summation-test"><i class="fas fa-link"></i></a>
</h3>
<p>The <strong>summation test</strong>, another second order test, looks for excessively large numbers in a dataset. It identifies numbers that are large compared to the norm for that data. The test was also proposed by <strong>Nigrini</strong><span class="citation"><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Mark J Nigrini, &lt;em&gt;Benford’s Law Applications for Forensic Accounting, Auditing and Fraud Detection&lt;/em&gt;, 1st ed. (John Wiley; Sons, Ltd, 2012), &lt;a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119203094.ch5"&gt;https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119203094.ch5&lt;/a&gt;.&lt;/p&gt;'><sup>43</sup></a></span> and it is based on the fact that the sums of all numbers in a Benford distribution with first-two digits (10, 11, 12, …99) should be the same. Therefore, for each of the 90 first-two digits groups sum proportions should be equal, i.e. 1/90 or 0.011. The spikes, if any indicate that there are some large single numbers or set of numbers.</p>
<p>In the next section, we will see how to implement all these tests through R.</p>
</div>
<div id="limitations-of-benford-tests" class="section level3" number="38.2.6">
<h3>
<span class="header-section-number">38.2.6</span> Limitations of Benford Tests<a class="anchor" aria-label="anchor" href="#limitations-of-benford-tests"><i class="fas fa-link"></i></a>
</h3>
<p>Benford’s Law may not hold in the following circumstances-</p>
<ol style="list-style-type: decimal">
<li>When the data-set is comprised of assigned numbers. Like cheque numbers, invoices numbers, telephone numbers, pincodes, etc.</li>
<li>Numbers that may be influenced viz. ATM withdrawals, etc.</li>
<li>Where amounts have either lower bound, or upper bounds or both. E.g. passengers onboard airplane, hourly wage rate, etc.</li>
<li>Count of transactions less than 500.</li>
</ol>
<p>Before carrying out analyics let us also see the evaluation metrics which will help us to evaluate the goodness of fit of data to Benford’s law. Three statistics are commonly used.</p>
</div>
</div>
<div id="goodness-of-fit-metrics" class="section level2" number="38.3">
<h2>
<span class="header-section-number">38.3</span> Goodness of fit metrics<a class="anchor" aria-label="anchor" href="#goodness-of-fit-metrics"><i class="fas fa-link"></i></a>
</h2>
<p>In table <a href="benford-testsanalysis.html#tab:tab1">38.3</a> we saw that digit frequencies largely followed Benford’s Law in six different datasets. However, as to evaluate how close is the actual distribution with theoretical distribution, we need to evaluate the fit on some metrics. Here we will use three different metrics as follows.</p>
<div id="chis" class="section level3" number="38.3.1">
<h3>
<span class="header-section-number">38.3.1</span> Chi-square statistic<a class="anchor" aria-label="anchor" href="#chis"><i class="fas fa-link"></i></a>
</h3>
<p>In first of these test, we will use Chi Square Statistic. This statistic is used to test the statistical significance to the whole distribution in observed frequency of first digit and first two digits against their expected frequency under Benford’s Law (BL). The <strong>Null hypothesis states that digits follow Benford’s Law.</strong> Mathematical formula is,</p>
<span class="math display" id="eq:ben3">\[\begin{equation}
\chi^2 = \sum_{i=1}^{9} \frac{(O_i - E_i)^2}{E_i}
\tag{38.3}
\end{equation}\]</span>
<p>where -</p>
<ul>
<li>
<span class="math inline">\(O_i\)</span> is the observed frequency of the i-th digit.</li>
<li>
<span class="math inline">\(E_i\)</span> is the expected frequency of the i-th digit predicted by Benford’s Law.</li>
</ul>
<p>This calculated chi-square statistic is compared to a critical value. The critical value for Chi-Square Test, comes from a chi-square distribution available easily in any Statistical textbook<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda3674.htm"&gt;https://www.itl.nist.gov/div898/handbook/eda/section3/eda3674.htm&lt;/a&gt;&lt;/p&gt;'><sup>44</sup></a>. However, for first digit test and first two digits test, the critical values are reproduced in Table <a href="benford-testsanalysis.html#tab:tab6">38.7</a>.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:tab6">Table 38.7: </span><span id="tab:tab6">Table 38.8: </span>Critical values for Chi-Square Test
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
First Digit Test
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Two Digit Test
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Degrees of Freedom
</th>
<th style="text-align:right;">
8
</th>
<th style="text-align:right;">
89
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
10%
</td>
<td style="text-align:right;">
13.362
</td>
<td style="text-align:right;">
106.469
</td>
</tr>
<tr>
<td style="text-align:left;">
5%
</td>
<td style="text-align:right;">
15.507
</td>
<td style="text-align:right;">
112.022
</td>
</tr>
<tr>
<td style="text-align:left;">
2.5%
</td>
<td style="text-align:right;">
17.535
</td>
<td style="text-align:right;">
116.989
</td>
</tr>
<tr>
<td style="text-align:left;">
1%
</td>
<td style="text-align:right;">
20.090
</td>
<td style="text-align:right;">
122.942
</td>
</tr>
<tr>
<td style="text-align:left;">
0.1%
</td>
<td style="text-align:right;">
26.125
</td>
<td style="text-align:right;">
135.978
</td>
</tr>
</tbody>
</table></div>
<p>To check goodness of fit, we have to compare calculated <span class="math inline">\(χ^2\)</span> statistic with these critical values. If the observed value is above these critical values we may conclude that our initial hypothesis that data follows BL, should be rejected. Or simply that data does not conforms Benford law/Distribution.</p>
<p>For example, in <code>census.2009</code> data the chi-square statistic calculates to <code>17.524</code> which is less than 2.5% critical value 17.535. Thus, we can say with 5% confidence that <code>census.2009</code> data follows BL (first digit law).</p>
</div>
<div id="z-score" class="section level3" number="38.3.2">
<h3>
<span class="header-section-number">38.3.2</span> Z-score<a class="anchor" aria-label="anchor" href="#z-score"><i class="fas fa-link"></i></a>
</h3>
<p>Z-statistic checks whether the individual distribution significantly differs from Benford’s Law distribution. Mathematically, Z-Statistics considers the absolute magnitude of the difference from actual to the expected, size of the data and expected proportion.</p>
<span class="math display" id="eq:ben4">\[\begin{equation}
Z = \frac{(\lvert p - p_0\rvert) - (\frac{1}{2n})}{\sqrt{\frac{p_0(1-p_0)}{n}}}
\tag{38.4}
\end{equation} \]</span>
<p>where -</p>
<ul>
<li>
<span class="math inline">\(p\)</span> is the observed frequency of the leading digits in the dataset.</li>
<li>
<span class="math inline">\(p_0\)</span> is the expected frequency under Benford’s Law.</li>
<li>
<span class="math inline">\(n\)</span> is the number of records</li>
</ul>
<p>In equation <a href="benford-testsanalysis.html#eq:ben4">(38.4)</a>, the last term in the numerator <span class="math inline">\(\frac{1}{2N}\)</span> is a continuity correction term and is used only when it is smaller than the first term in the numerator. Mark Nigrini has proposed that if the values of Z-statistic exceed the critical value 1.96, the null hypothesis <span class="math inline">\(H_{0A}\)</span> is rejected at 5% of significance level. Also note that <strong>Null hypothesis is same, which states that digits follow Benford’s Law.</strong></p>
<p>If the significant levels are 1% or 10%, the corresponding critical values are 2.57 and 1.64 respectively.</p>
</div>
<div id="mean-absolute-deviation" class="section level3" number="38.3.3">
<h3>
<span class="header-section-number">38.3.3</span> Mean absolute deviation<a class="anchor" aria-label="anchor" href="#mean-absolute-deviation"><i class="fas fa-link"></i></a>
</h3>
<p>Another Statistic, Mean Absolute Deviation also sometimes referred to as <strong>M.A.D.</strong>, measures absolute deviations of observed frequencies from theoritical ones. The mathematical formula is written in equation <a href="benford-testsanalysis.html#eq:ben5">(38.5)</a>.</p>
<p><span class="math display" id="eq:ben5">\[\begin{equation}
MAD = \frac{1}{9} \sum_{i=1}^{9} |O_i - E_i|
\tag{38.5}
\end{equation}\]</span></p>
<p>As there are no objective critical scores for the absolute deviations, the critical values prescribed by Mark J Nigrini are -</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:tab7">Table 38.9: </span> Critical Scores for MAD test</caption>
<colgroup>
<col width="26%">
<col width="24%">
<col width="24%">
<col width="24%">
</colgroup>
<thead><tr class="header">
<th>First Digits</th>
<th></th>
<th>First-Two Digits</th>
<th></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>0.000 to 0.006</td>
<td>Close conformity</td>
<td>0.000 to 0.012</td>
<td>Close conformity</td>
</tr>
<tr class="even">
<td>0.006 to 0.012</td>
<td>Acceptable conformity</td>
<td>0.012 to 0.018</td>
<td>Acceptable conformity</td>
</tr>
<tr class="odd">
<td>0.012 to 0.015</td>
<td>Marginally acceptable conformity</td>
<td>0.018 to 0.022</td>
<td>Marginally acceptable conformity</td>
</tr>
<tr class="even">
<td>above 0.015</td>
<td>Nonconformity</td>
<td>above 0.022</td>
<td>Nonconformity</td>
</tr>
</tbody>
</table></div>
</div>
<div id="other-descriptive-statistics" class="section level3" number="38.3.4">
<h3>
<span class="header-section-number">38.3.4</span> Other descriptive Statistics<a class="anchor" aria-label="anchor" href="#other-descriptive-statistics"><i class="fas fa-link"></i></a>
</h3>
<p>If the data follows Benford’s Law, the numbers should be close to those shown in table following, as suggested by Mark Nigrini.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:benford">Table 38.10: </span> Ideal Statistics for data that follows Benford’s Law</caption>
<thead><tr class="header">
<th align="center">Statistic</th>
<th align="center">Value</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">Mean</td>
<td align="center">0.5</td>
</tr>
<tr class="even">
<td align="center">Variance</td>
<td align="center">1/12 (0.08333…)</td>
</tr>
<tr class="odd">
<td align="center">Ex. Kurtosis</td>
<td align="center">-1.2</td>
</tr>
<tr class="even">
<td align="center">Skewness</td>
<td align="center">0</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div id="important" class="section level2" number="38.4">
<h2>
<span class="header-section-number">38.4</span> Important<a class="anchor" aria-label="anchor" href="#important"><i class="fas fa-link"></i></a>
</h2>
<p>Benford’s Law analysis serves as a powerful tool in uncovering potential irregularities in datasets, but it’s crucial to note that deviations from this statistical phenomenon don’t always signify fraudulent activities. While it highlights notable discrepancies between expected and observed frequencies of digits in naturally occurring datasets, these variations might stem from various legitimate factors such as data entry errors, fluctuations in processes, or different sources of data. Understanding that Benford’s Law offers a signal rather than a definitive confirmation of fraud allows for a more nuanced interpretation, encouraging further investigation to discern the true nature behind these deviations.</p>
<p>Conversely, just because a dataset adheres to Benford’s Law, it doesn’t guarantee the absence of fraud. While conformity to this statistical principle generally suggests consistency within the data, sophisticated fraudsters might deliberately manipulate information to mimic expected distributions, masking their illicit activities. Therefore, while adherence to Benford’s Law might lessen suspicion, it doesn’t serve as an absolute assurance against fraudulent behavior.</p>
<p>Benford’s Law acting as a warning signal indicates potential irregularities in the numbers. It’s vital to dive deeper and investigate why these figures seem odd. Further scrutiny helps differentiate between a minor data hiccup and a potentially significant issue. This additional examination might mean cross-checking other data, validating records, or engaging with those connected to the information. This thorough approach is crucial for unraveling the story behind these uncommon figures.</p>
</div>
<div id="pracben" class="section level2" number="38.5">
<h2>
<span class="header-section-number">38.5</span> Practical approach in R<a class="anchor" aria-label="anchor" href="#pracben"><i class="fas fa-link"></i></a>
</h2>
<p>As already stated we will use package <code>benford.analysis</code> for carrying out analytics on Benford’s Law, in R. Let us load it.</p>
<div class="sourceCode" id="cb1926"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://github.com/carloscinelli/benford.analysis">benford.analysis</a></span><span class="op">)</span></span></code></pre></div>
<p>This package provides tools that make it easier to validate data using Benford’s Law. This package has been developed by <strong>Carlos Cinelli</strong>. As the package author himself states that the main purpose of the package is to identify suspicious data that need further verification, it should always be kept in mind that these analytics only provide us red-flagged transactions that should be validated further.</p>
<p>Apart from useful functions in the package, this also loads some default datasets specially those which were used by Frank Benford while proposing his law. Let us load the census 2009 data containing the population of towns and cities of the United States, as of July of 2009.</p>
<div class="sourceCode" id="cb1927"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"census.2009"</span><span class="op">)</span></span></code></pre></div>
<p>Let us view the top 6 rows of the data.</p>
<div class="sourceCode" id="cb1928"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">census.2009</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     state             town pop.2009
## 1 Alabama   Abbeville city     2930
## 2 Alabama  Adamsville city     4782
## 3 Alabama     Addison town      709
## 4 Alabama       Akron town      433
## 5 Alabama   Alabaster city    29861
## 6 Alabama Albertville city    20115</code></pre>
<p>In fact, this contains 19509 records.</p>
<p><strong>Problem Statement:</strong> Let us test Benford’s law on 2009 population data. Let us see whether the data conforms Benford’s law.</p>
<p>The main function <code><a href="https://rdrr.io/pkg/benford.analysis/man/benford.html">benford()</a></code> takes a vector of values to be tested as input, and creates an output of special class <code>benford</code> The syntax is</p>
<pre><code>benford(data, number.of.digits=2)</code></pre>
<p>where-</p>
<ul>
<li>
<code>data</code> is numeric vector on which analysis has to be performed.</li>
<li>
<code>number.of.digits</code> is number of digits on which analysis has to be performed. Default value is <code>2</code>.</li>
</ul>
<div class="sourceCode" id="cb1931"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">census_first_digit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/benford.html">benford</a></span><span class="op">(</span><span class="va">census.2009</span><span class="op">$</span><span class="va">pop.2009</span>, number.of.digits <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p>Above syntax will create <code>census_first_digit</code> object which store various useful information for Benford Analytics. We may view its summary -</p>
<div class="sourceCode" id="cb1932"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">census_first_digit</span><span class="op">)</span></span></code></pre></div>
<pre><code>##                   Length Class      Mode     
## info               4     -none-     list     
## data               4     data.table list     
## s.o.data           2     data.table list     
## bfd               13     data.table list     
## mantissa           2     data.table list     
## MAD                1     -none-     numeric  
## MAD.conformity     1     -none-     character
## distortion.factor  1     -none-     numeric  
## stats              2     -none-     list</code></pre>
<p>Let us also print the object to see what all is stored therein.</p>
<div class="sourceCode" id="cb1934"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">census_first_digit</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Benford object:
##  
## Data: census.2009$pop.2009 
## Number of observations used = 19509 
## Number of obs. for second order = 7950 
## First digits analysed = 1
## 
## Mantissa: 
## 
##    Statistic  Value
##         Mean  0.503
##          Var  0.084
##  Ex.Kurtosis -1.207
##     Skewness -0.013
## 
## 
## The 5 largest deviations: 
## 
##   digits absolute.diff
## 1      1        134.79
## 2      2        104.64
## 3      3         95.43
## 4      6         63.94
## 5      8         45.07
## 
## Stats:
## 
##  Pearson's Chi-squared test
## 
## data:  census.2009$pop.2009
## X-squared = 17.524, df = 8, p-value = 0.0251
## 
## 
##  Mantissa Arc Test
## 
## data:  census.2009$pop.2009
## L2 = 4.198e-05, df = 2, p-value = 0.4409
## 
## Mean Absolute Deviation (MAD): 0.003119261
## MAD Conformity - Nigrini (2012): Close conformity
## Distortion Factor: 0.7404623
## 
## Remember: Real data will never conform perfectly to Benford's Law. You should not focus on p-values!</code></pre>
<p>Results of Chi-Square distribution test, MAD etc. are printed apart from top deviations. The MAD value of <code>0.003</code> shows <code>close conformity</code> with Benford’s law. Chi Square statistic at 17.524 is slightly greater than 5% critical value of 15.507. In second example we will see that results of <code>print</code> command on benford object can be further customised, using its other arguments.</p>
<p>Let us also visualise the plots. We will use <code>plot</code> command to generate the plots.</p>
<div class="sourceCode" id="cb1936"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">census_first_digit</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:cenbenplot"></span>
<img src="DauR_files/figure-html/cenbenplot-1.png" alt="Benford Analysis Results of Census 2009 Data" width="672"><p class="caption">
Figure 38.6: Benford Analysis Results of Census 2009 Data
</p>
</div>
<p>We can see that by default five charts are printed.</p>
<ol style="list-style-type: decimal">
<li>Digits distribution</li>
<li>Second Order Test digit distribution</li>
<li>Summation test - digit distribution</li>
<li>Chi-Square differences</li>
<li>Summation differences</li>
</ol>
<p><em>Similarly, in second example we will see how to customise plot outputs.</em></p>
<p>We can see that first digits in census 2009 data, follows Benford’s Law closely.</p>
<div id="other-useful-functions-in-package" class="section level3" number="38.5.1">
<h3>
<span class="header-section-number">38.5.1</span> Other Useful functions in package<a class="anchor" aria-label="anchor" href="#other-useful-functions-in-package"><i class="fas fa-link"></i></a>
</h3>
<p>You may be wondering whether we have to depend upon print function every time to get analytics insights out the object created. In fact there are several other functions in this package which are very useful while carrying out risk analysis through Benford’s Law.</p>
<ul>
<li>
<code>chisq</code>: Gets the Chi-squared test of a Benford object. Takes a benford object as input.</li>
<li>
<code>duplicatesTable</code> Shows the duplicates of the data. Similarly, takes a benford object as input.</li>
<li>
<code>extract.digits</code> Extracts the leading digits from the data. Takes data as input. This is useful, while carrying out analysis manually.</li>
<li>
<code>getBfd</code> Gets the the statistics of the first Digits of a benford object. E.g.</li>
</ul>
<div class="sourceCode" id="cb1937"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/getBfd.html">getBfd</a></span><span class="op">(</span><span class="va">census_first_digit</span><span class="op">)</span></span></code></pre></div>
<pre><code>##    digits  data.dist data.second.order.dist benford.dist
##     &lt;int&gt;      &lt;num&gt;                  &lt;num&gt;        &lt;num&gt;
## 1:      1 0.29412066             0.55811321   0.30103000
## 2:      2 0.18145471             0.15471698   0.17609126
## 3:      3 0.12004716             0.08968553   0.12493874
## 4:      4 0.09467425             0.05761006   0.09691001
## 5:      5 0.07991184             0.04364780   0.07918125
## 6:      6 0.07022400             0.03308176   0.06694679
## 7:      7 0.05976729             0.02553459   0.05799195
## 8:      8 0.05346250             0.01987421   0.05115252
## 9:      9 0.04633759             0.01773585   0.04575749
##    data.second.order.dist.freq data.dist.freq benford.dist.freq
##                          &lt;num&gt;          &lt;num&gt;             &lt;num&gt;
## 1:                        4437           5738         5872.7942
## 2:                        1230           3540         3435.3644
## 3:                         713           2342         2437.4298
## 4:                         458           1847         1890.6174
## 5:                         347           1559         1544.7469
## 6:                         263           1370         1306.0649
## 7:                         203           1166         1131.3649
## 8:                         158           1043          997.9346
## 9:                         141            904          892.6829
##    benford.so.dist.freq data.summation abs.excess.summation difference
##                   &lt;num&gt;          &lt;num&gt;                &lt;num&gt;      &lt;num&gt;
## 1:            2393.1885       51237849             29880783 -134.79419
## 2:            1399.9255       33272136             11915070  104.63563
## 3:             993.2630       22810354              1453288  -95.42981
## 4:             770.4346       15763499              5593567  -43.61744
## 5:             629.4909       15799838              5557228   14.25307
## 6:             532.2270       14527377              6829689   63.93508
## 7:             461.0360       11371006              9986060   34.63511
## 8:             406.6626       18814056              2543010   45.06544
## 9:             363.7720        8617475             12739591   11.31712
##    squared.diff absolute.diff
##           &lt;num&gt;         &lt;num&gt;
## 1:    3.0938378     134.79419
## 2:    3.1870315     104.63563
## 3:    3.7362508      95.42981
## 4:    1.0062752      43.61744
## 5:    0.1315102      14.25307
## 6:    3.1297790      63.93508
## 7:    1.0603039      34.63511
## 8:    2.0350972      45.06544
## 9:    0.1434744      11.31712</code></pre>
<ul>
<li>
<code>getSuspects</code> Gets the ‘suspicious’ observations according to Benford’s Law. Takes both data as well as benford object, as inputs. Example in second case study.</li>
<li>
<code>MAD</code> Gets the MAD of a Benford object.</li>
<li>
<code>suspectsTable</code> Shows the first digits ordered by the mains discrepancies from Benford’s Law. Notice the difference from <code>getSuspects</code>
</li>
</ul>
</div>
<div id="example-2-corporate-payments-data" class="section level3" number="38.5.2">
<h3>
<span class="header-section-number">38.5.2</span> Example-2: Corporate payments data<a class="anchor" aria-label="anchor" href="#example-2-corporate-payments-data"><i class="fas fa-link"></i></a>
</h3>
<p><strong>Problem Statement-2:</strong> Let us analyse red-flags, on dataset of the 2010’s payments data (189470 records) of a division of a West Coast utility company. This data, <code>corporate.payments</code> is also available with the package. This time we will use first two digits in our analysis.</p>
<p><strong>Step-1:</strong> Load the dataset and view its top rows. Let’s also see its summary.</p>
<div class="sourceCode" id="cb1939"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"corporate.payment"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">corporate.payment</span><span class="op">)</span></span></code></pre></div>
<pre><code>##   VendorNum       Date  InvNum Amount
## 1      2001 2010-01-02 0496J10  36.08
## 2      2001 2010-01-02 1726J10  77.80
## 3      2001 2010-01-02 2104J10  34.97
## 4      2001 2010-01-02 2445J10  59.00
## 5      2001 2010-01-02 3281J10  59.56
## 6      2001 2010-01-02 3822J10  50.38</code></pre>
<div class="sourceCode" id="cb1941"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">corporate.payment</span><span class="op">)</span></span></code></pre></div>
<pre><code>##   VendorNum              Date               InvNum              Amount        
##  Length:189470      Min.   :2010-01-02   Length:189470      Min.   :  -71388  
##  Class :character   1st Qu.:2010-02-28   Class :character   1st Qu.:      50  
##  Mode  :character   Median :2010-06-04   Mode  :character   Median :     200  
##                     Mean   :2010-06-16                      Mean   :    2588  
##                     3rd Qu.:2010-09-30                      3rd Qu.:     835  
##                     Max.   :2010-12-31                      Max.   :26763476</code></pre>
<p>We can see it has 189470 records having</p>
<pre><code>+   Vendor Numbers
+   Date of Transaction
+   Invoice Number
+   Amount of invoice/transaction</code></pre>
<p><strong>Step-2:</strong> Create benford object</p>
<div class="sourceCode" id="cb1944"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">corp_bfd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/benford.html">benford</a></span><span class="op">(</span><span class="va">corporate.payment</span><span class="op">$</span><span class="va">Amount</span>, number.of.digits <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p><strong>Step-3:</strong> Let us first visually inspect the results. This time we will use another argument of <code>plot</code> function in <code>benford.analysis</code> library which is <code>except</code>. Actually this can create seven different plots and by default it creates five plots as stated earlier. Thus, by writing <code>except = "none"</code> we can include all seven plots if we want. Otherwise we will have to mention exclusions from <code>c("digits", "second order", "summation", "mantissa", "chi squared", "abs diff", "ex summation")</code>. There is one more argument namely <code>multiple</code> which is TRUE by default and plots multiple charts in same window.</p>
<p>So let us build (i) Digit distribution and (ii) Second order digit distribution plots.</p>
<div class="sourceCode" id="cb1945"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span></span>
<span>  <span class="va">corp_bfd</span>,</span>
<span>  except <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>    <span class="st">"summation"</span>,</span>
<span>    <span class="st">"mantissa"</span>,</span>
<span>    <span class="st">"chi squared"</span>,</span>
<span>    <span class="st">"abs diff"</span>,</span>
<span>    <span class="st">"ex summation"</span>,</span>
<span>    <span class="st">"chisq diff"</span>,</span>
<span>    <span class="st">"legend"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  multiple <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:corpben"></span>
<img src="DauR_files/figure-html/corpben-1.png" alt="Benford Analysis results on Corporate payments Data" width="47%" height="30%"><img src="DauR_files/figure-html/corpben-2.png" alt="Benford Analysis results on Corporate payments Data" width="47%" height="30%"><p class="caption">
Figure 38.7: Benford Analysis results on Corporate payments Data
</p>
</div>
<p>We can see that largely the data follows Benford’s Law except an abnormal peak at 50.</p>
<p><strong>Step-4:</strong> Let us now see what is inside of this object. Function <code>print</code> in <code>benford.analysis</code> package has another argument <code>how.many</code> which simply tells us to print how many of the absolute differences.</p>
<div class="sourceCode" id="cb1946"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">corp_bfd</span>, how.many <span class="op">=</span> <span class="fl">7</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Benford object:
##  
## Data: corporate.payment$Amount 
## Number of observations used = 185083 
## Number of obs. for second order = 65504 
## First digits analysed = 2
## 
## Mantissa: 
## 
##    Statistic  Value
##         Mean  0.496
##          Var  0.092
##  Ex.Kurtosis -1.257
##     Skewness -0.002
## 
## 
## The 7 largest deviations: 
## 
##   digits absolute.diff
## 1     50       5938.25
## 2     11       3331.98
## 3     10       2811.92
## 4     14       1043.68
## 5     98        889.95
## 6     90        736.81
## 7     92        709.01
## 
## Stats:
## 
##  Pearson's Chi-squared test
## 
## data:  corporate.payment$Amount
## X-squared = 32094, df = 89, p-value &lt; 2.2e-16
## 
## 
##  Mantissa Arc Test
## 
## data:  corporate.payment$Amount
## L2 = 0.0039958, df = 2, p-value &lt; 2.2e-16
## 
## Mean Absolute Deviation (MAD): 0.002336614
## MAD Conformity - Nigrini (2012): Nonconformity
## Distortion Factor: -1.065467
## 
## Remember: Real data will never conform perfectly to Benford's Law. You should not focus on p-values!</code></pre>
<p>We can see that digit 50 has indeed the largest abolute difference. One of the reasons for availability of invoices in this digit group may be due to some tax capping or some other reason, which an auditor may need to investigate further.</p>
<p>Using <code><a href="https://rdrr.io/pkg/benford.analysis/man/suspectsTable.html">suspectsTable()</a></code> we can also get similar information.</p>
<div class="sourceCode" id="cb1948"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/suspectsTable.html">suspectsTable</a></span><span class="op">(</span><span class="va">corp_bfd</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">7</span><span class="op">)</span></span></code></pre></div>
<pre><code>##    digits absolute.diff
##     &lt;int&gt;         &lt;num&gt;
## 1:     50     5938.2544
## 2:     11     3331.9798
## 3:     10     2811.9177
## 4:     14     1043.6833
## 5:     98      889.9470
## 6:     90      736.8084
## 7:     92      709.0129</code></pre>
<p><strong>Step-5:</strong> Let us also get the Chi Square and other metrics</p>
<div class="sourceCode" id="cb1950"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/chisq.html">chisq</a></span><span class="op">(</span><span class="va">corp_bfd</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
##  Pearson's Chi-squared test
## 
## data:  corporate.payment$Amount
## X-squared = 32094, df = 89, p-value &lt; 2.2e-16</code></pre>
<p>Going strictly by numbers and p-value, which we should not depend upon in Benford Analytics, we see that Null hypothesis (Ref: section <a href="benford-testsanalysis.html#chis">38.3.1</a>) has been rejected. In other words, chi-square statistic tells us that data does not follow Benford Law.</p>
<p>To get Mean Absolute Deviation</p>
<div class="sourceCode" id="cb1952"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/MAD.html">MAD</a></span><span class="op">(</span><span class="va">corp_bfd</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.002336614</code></pre>
<p>Whether the value conforms to values suggested by Mark Nigrini, we can do</p>
<div class="sourceCode" id="cb1954"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">corp_bfd</span><span class="op">$</span><span class="va">MAD.conformity</span></span></code></pre></div>
<pre><code>## [1] "Nonconformity"</code></pre>
<p><strong>Step-6:</strong> Let us generate duplicate values avilable if any, in the data. For sake of brevity here, we will print top-5 results.</p>
<div class="sourceCode" id="cb1956"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/duplicatesTable.html">duplicatesTable</a></span><span class="op">(</span><span class="va">corp_bfd</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     number duplicates
##      &lt;num&gt;      &lt;int&gt;
## 1:   50.00       6022
## 2: 1153.35       2264
## 3: 1083.45       1185
## 4:  150.00       1056
## 5:  988.35       1018</code></pre>
<p>Examining output above, we can see that there are 6022 invoices having all amount of USD50 each. Probably this could be the reason for failing of null hypothesis in the data.</p>
<p><strong>Step-7:</strong> We can extract all distribution data using <code>getBFD</code> function.</p>
<div class="sourceCode" id="cb1958"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/getBfd.html">getBfd</a></span><span class="op">(</span><span class="va">corp_bfd</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     digits  data.dist data.second.order.dist benford.dist
##      &lt;int&gt;      &lt;num&gt;                  &lt;num&gt;        &lt;num&gt;
##  1:     10 0.05658542            0.374786273   0.04139269
##  2:     11 0.05579119            0.015922692   0.03778856
##  3:     12 0.03236926            0.014609795   0.03476211
##  4:     13 0.03116440            0.013266365   0.03218468
##  5:     14 0.02432422            0.011113825   0.02996322
##  6:     15 0.03038637            0.011510747   0.02802872
##  7:     16 0.02385416            0.010365779   0.02632894
##  8:     17 0.02179563            0.009129213   0.02482358
##  9:     18 0.02085011            0.009358207   0.02348110
## 10:     19 0.02043408            0.008106375   0.02227639
##     data.second.order.dist.freq data.dist.freq benford.dist.freq
##                           &lt;num&gt;          &lt;num&gt;             &lt;num&gt;
##  1:                       24550          10473          7661.082
##  2:                        1043          10326          6994.020
##  3:                         957           5991          6433.875
##  4:                         869           5768          5956.838
##  5:                         728           4502          5545.683
##  6:                         754           5624          5187.640
##  7:                         679           4415          4873.039
##  8:                         598           4034          4594.423
##  9:                         613           3859          4345.952
## 10:                         531           3782          4122.982
##     benford.so.dist.freq data.summation abs.excess.summation difference
##                    &lt;num&gt;          &lt;num&gt;                &lt;num&gt;      &lt;num&gt;
##  1:             2711.386       28701407             23224143  2811.9177
##  2:             2475.302       22324748             16847484  3331.9798
##  3:             2277.057       16258127             10780863  -442.8749
##  4:             2108.225       15520165             10042901  -188.8378
##  5:             1962.711       27393259             21915996 -1043.6833
##  6:             1835.994       49191988             43714724   436.3597
##  7:             1724.651       12523174              7045911  -458.0390
##  8:             1626.044       11994778              6517515  -560.4233
##  9:             1538.106        7545939              2068675  -486.9517
## 10:             1459.193        6987397              1510133  -340.9820
##     squared.diff absolute.diff
##            &lt;num&gt;         &lt;num&gt;
##  1:  1032.084049     2811.9177
##  2:  1587.368773     3331.9798
##  3:    30.485235      442.8749
##  4:     5.986347      188.8378
##  5:   196.418497     1043.6833
##  6:    36.704517      436.3597
##  7:    43.053153      458.0390
##  8:    68.359901      560.4233
##  9:    54.561565      486.9517
## 10:    28.200147      340.9820</code></pre>
<p><strong>Step-8:</strong> To get suspected/high risk records, we may make use of <code>getSuspects</code> function. As already stated it requires both benford object and data as inputs.</p>
<div class="sourceCode" id="cb1960"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># We are printing 10 records only</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/getSuspects.html">getSuspects</a></span><span class="op">(</span><span class="va">corp_bfd</span>, <span class="va">corporate.payment</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     VendorNum       Date      InvNum  Amount
##        &lt;char&gt;     &lt;Date&gt;      &lt;char&gt;   &lt;num&gt;
##  1:      2001 2010-01-02     3822J10   50.38
##  2:      2001 2010-01-07    100107-2 1166.29
##  3:      2001 2010-01-08 11210084007 1171.45
##  4:      2001 2010-01-08     1585J10   50.42
##  5:      2001 2010-01-08     4733J10  113.34
##  6:      2001 2010-01-08     6263J10  117.22
##  7:      2001 2010-01-08     6673J10   50.80
##  8:      2001 2010-01-08     9181J10  114.78
##  9:      2001 2010-01-09     1510J10   50.49
## 10:      2001 2010-01-09     1532J10   50.45</code></pre>
<p>Moreover, by using <code>slice_max</code> function from <code>dplyr</code> we can also get <code>n</code> high-valued ‘suspects’.</p>
<div class="sourceCode" id="cb1962"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/getSuspects.html">getSuspects</a></span><span class="op">(</span><span class="va">corp_bfd</span>, <span class="va">corporate.payment</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/slice.html">slice_max</a></span><span class="op">(</span>order_by <span class="op">=</span> <span class="va">Amount</span>, n <span class="op">=</span> <span class="fl">10</span>, with_ties <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     VendorNum       Date                InvNum    Amount
##        &lt;char&gt;     &lt;Date&gt;                &lt;char&gt;     &lt;num&gt;
##  1:      2817 2010-10-27                10-10A 1156428.2
##  2:     17141 2010-04-05                040510 1135003.6
##  3:      2817 2010-11-30            1033500002 1112304.3
##  4:     16721 2010-09-16 SEE ATTACHED BALSHEET 1100000.0
##  5:      6118 2010-12-17             103511001  509093.7
##  6:      2817 2010-05-28                 40821  506971.5
##  7:     17284 2010-03-24                032400  504580.6
##  8:      6118 2010-08-26             102381001  504334.6
##  9:     17284 2010-03-10                 31000  502132.2
## 10:      2088 2010-03-24            1008300003  500000.0</code></pre>
<div id="conclusion" class="section level4 unnumbered">
<h4>Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"><i class="fas fa-link"></i></a>
</h4>
<p>Though by statistics (goodness of fit metrics), the data did not conform to BL, yet we observed that there were abnormally high records starting with digits <code>50</code>. The reasons can be further investigated. By charts we also observed that, otherwise the data conform to BL. We also extracted suspected records for further investigation on other parameters/tests/verification. To sum up, we can say that, Benford Analysis can be a good starting point for fraud/forensic analytics while auditing. Before closing, let us also delve in one other example.</p>
</div>
</div>
<div id="example-3-lakes-perimeter" class="section level3" number="38.5.3">
<h3>
<span class="header-section-number">38.5.3</span> Example-3: Lakes Perimeter<a class="anchor" aria-label="anchor" href="#example-3-lakes-perimeter"><i class="fas fa-link"></i></a>
</h3>
<p>Let us apply this on <code>lakes.perimeter</code><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;A dataset of the perimeter of the lakes arround the water from the global lakes and wetlands database (GLWD) &lt;a href="http://www.worldwildlife.org/pages/global-lakes-and-wetlands-database" class="uri"&gt;http://www.worldwildlife.org/pages/global-lakes-and-wetlands-database&lt;/a&gt;&lt;/p&gt;'><sup>45</sup></a> data which is available with the package.</p>
<div class="sourceCode" id="cb1964"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># load sample data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">lakes.perimeter</span><span class="op">)</span> </span>
<span><span class="co"># Number of rows</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">lakes.perimeter</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 248607</code></pre>
<div class="sourceCode" id="cb1966"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># View top rows</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">lakes.perimeter</span><span class="op">)</span></span></code></pre></div>
<pre><code>##   perimeter.km
## 1          1.0
## 2          1.0
## 3          1.1
## 4          1.1
## 5          1.1
## 6          1.1</code></pre>
<div class="sourceCode" id="cb1968"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Generate Benford Object</span></span>
<span><span class="va">lake_ben</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/benford.html">benford</a></span><span class="op">(</span><span class="va">lakes.perimeter</span><span class="op">$</span><span class="va">perimeter.km</span>, number.of.digits <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p>Let us see the plots, metrics and top outliers</p>
<div class="sourceCode" id="cb1969"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">lake_ben</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-569"></span>
<img src="DauR_files/figure-html/unnamed-chunk-569-1.png" alt="Benford Analysis - lake Perimeter Data" width="672"><p class="caption">
Figure 38.8: Benford Analysis - lake Perimeter Data
</p>
</div>
<div class="sourceCode" id="cb1970"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Chisq test</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/chisq.html">chisq</a></span><span class="op">(</span><span class="va">lake_ben</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
##  Pearson's Chi-squared test
## 
## data:  lakes.perimeter$perimeter.km
## X-squared = 88111, df = 89, p-value &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb1972"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># MAD</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/MAD.html">MAD</a></span><span class="op">(</span><span class="va">lake_ben</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.006012766</code></pre>
<div class="sourceCode" id="cb1974"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Whether it conforms?</span></span>
<span><span class="va">lake_ben</span><span class="op">$</span><span class="va">MAD.conformity</span></span></code></pre></div>
<pre><code>## [1] "Nonconformity"</code></pre>
<div class="sourceCode" id="cb1976"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Get top-10 suspects</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/getSuspects.html">getSuspects</a></span><span class="op">(</span><span class="va">lake_ben</span>, <span class="va">lakes.perimeter</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     perimeter.km
##            &lt;num&gt;
##  1:          1.5
##  2:          1.5
##  3:          1.5
##  4:          1.5
##  5:          1.5
##  6:          1.5
##  7:          1.5
##  8:          1.5
##  9:          1.5
## 10:          1.5</code></pre>
<div class="sourceCode" id="cb1978"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Get top-10 suspects on Squared Differences</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/getSuspects.html">getSuspects</a></span><span class="op">(</span><span class="va">lake_ben</span>, <span class="va">lakes.perimeter</span>, </span>
<span>            by <span class="op">=</span> <span class="st">"squared.diff"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     perimeter.km
##            &lt;num&gt;
##  1:          3.6
##  2:          3.6
##  3:          3.6
##  4:          3.6
##  5:          3.6
##  6:          3.6
##  7:          3.6
##  8:          3.6
##  9:          3.6
## 10:          3.6</code></pre>
<div class="sourceCode" id="cb1980"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Get top-10 suspects on Absolute Excess Summation</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/benford.analysis/man/getSuspects.html">getSuspects</a></span><span class="op">(</span><span class="va">lake_ben</span>, <span class="va">lakes.perimeter</span>, </span>
<span>            by <span class="op">=</span> <span class="st">"abs.excess.summation"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     perimeter.km
##            &lt;num&gt;
##  1:          1.0
##  2:          1.0
##  3:          1.3
##  4:          1.3
##  5:          1.3
##  6:          1.3
##  7:          1.3
##  8:          1.3
##  9:          1.3
## 10:          1.3</code></pre>
<div id="conclusion-1" class="section level4 unnumbered">
<h4>Conclusion<a class="anchor" aria-label="anchor" href="#conclusion-1"><i class="fas fa-link"></i></a>
</h4>
<p>We observed that data does not conform Benford’s law which is evident from plot as well as MAD value. Chi-Squared Value of <code>88111</code> also exceeds critical value very significantly. Nigrini and Miller gave some plausible explanations in their Research paper<span class="citation"><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Mark Nigrini and Steven Miller, &lt;span&gt;“Benford’s Law Applied to Hydrology Data—Results and Relevance to Other Geophysical Data,”&lt;/span&gt; &lt;em&gt;Mathematical Geology&lt;/em&gt; 39 (September 2007): 469–90, &lt;a href="https://doi.org/10.1007/s11004-007-9109-5"&gt;https://doi.org/10.1007/s11004-007-9109-5&lt;/a&gt;.&lt;/p&gt;'><sup>46</sup></a></span> for this non-conformity. One of the possible reasons, they propose, was that <em>perimeter is not a correct measurement for the size of a lake.</em></p>
</div>
</div>
</div>
<div id="conclusion-2" class="section level2" number="38.6">
<h2>
<span class="header-section-number">38.6</span> Conclusion<a class="anchor" aria-label="anchor" href="#conclusion-2"><i class="fas fa-link"></i></a>
</h2>
<p>As we conclude this chapter on Benford Analytics, it’s clear that this statistical phenomenon holds remarkable potential across diverse fields. The inherent simplicity of Benford’s Law belies its complexity and applicability. Its ability to unveil anomalies, authenticate data integrity, and aid in forensic investigations underscores its significance in modern data analysis. As we delve deeper into its intricacies and practical applications, we unravel a tool that not only scrutinizes numbers but also illuminates new avenues for precision, authenticity, and trust in our data-driven world.</p>
<hr>
<p>Further Reading-</p>
<ol style="list-style-type: decimal">
<li><p>ISACA JOURNAL ARCHIVES - <a href="https://www.isaca.org/resources/isaca-journal/past-issues/2011/understanding-and-applying-benfords-law">Understanding and Applying Benford’s Law - 1 May 2011</a></p></li>
<li><p>Newcomb, Simon. “Note on the Frequency of Use of the Different Digits in Natural Numbers.” American Journal of Mathematics, vol. 4, no. 1, 1881, pp. 39–40. JSTOR, <a href="https://doi.org/10.2307/2369148" class="uri">https://doi.org/10.2307/2369148</a>. Accessed 15 Jun. 2022.</p></li>
<li><p>Durtschi, Cindy &amp; Hillison, William &amp; Pacini, Carl. (2004). The Effective Use of Benford’s Law to Assist in Detecting Fraud in Accounting Data. J. Forensic Account.</p></li>
</ol>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="part-ix-identifying-anamolous-observations-for-audit.html">Part-IX: Identifying anamolous observations for audit</a></div>
<div class="next"><a href="anomaly-detection.html"><span class="header-section-number">39</span> Anomaly Detection</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#benford-testsanalysis"><span class="header-section-number">38</span> Benford Tests/Analysis</a></li>
<li><a class="nav-link" href="#introduction-and-historical-context"><span class="header-section-number">38.1</span> Introduction and Historical context</a></li>
<li>
<a class="nav-link" href="#benfords-law-properties-and-extensions"><span class="header-section-number">38.2</span> Benford’s Law, properties and extensions</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#law-of-first-digit"><span class="header-section-number">38.2.1</span> Law of first digit</a></li>
<li><a class="nav-link" href="#scale-invariance"><span class="header-section-number">38.2.2</span> Scale Invariance</a></li>
<li><a class="nav-link" href="#first-two-digits"><span class="header-section-number">38.2.3</span> First two digits</a></li>
<li><a class="nav-link" href="#second-order-test"><span class="header-section-number">38.2.4</span> Second order test</a></li>
<li><a class="nav-link" href="#summation-test"><span class="header-section-number">38.2.5</span> Summation Test</a></li>
<li><a class="nav-link" href="#limitations-of-benford-tests"><span class="header-section-number">38.2.6</span> Limitations of Benford Tests</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#goodness-of-fit-metrics"><span class="header-section-number">38.3</span> Goodness of fit metrics</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#chis"><span class="header-section-number">38.3.1</span> Chi-square statistic</a></li>
<li><a class="nav-link" href="#z-score"><span class="header-section-number">38.3.2</span> Z-score</a></li>
<li><a class="nav-link" href="#mean-absolute-deviation"><span class="header-section-number">38.3.3</span> Mean absolute deviation</a></li>
<li><a class="nav-link" href="#other-descriptive-statistics"><span class="header-section-number">38.3.4</span> Other descriptive Statistics</a></li>
</ul>
</li>
<li><a class="nav-link" href="#important"><span class="header-section-number">38.4</span> Important</a></li>
<li>
<a class="nav-link" href="#pracben"><span class="header-section-number">38.5</span> Practical approach in R</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#other-useful-functions-in-package"><span class="header-section-number">38.5.1</span> Other Useful functions in package</a></li>
<li><a class="nav-link" href="#example-2-corporate-payments-data"><span class="header-section-number">38.5.2</span> Example-2: Corporate payments data</a></li>
<li><a class="nav-link" href="#example-3-lakes-perimeter"><span class="header-section-number">38.5.3</span> Example-3: Lakes Perimeter</a></li>
</ul>
</li>
<li><a class="nav-link" href="#conclusion-2"><span class="header-section-number">38.6</span> Conclusion</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>R for Audit Analytics</strong>" was written by Anil Goyal. It was last built on 2024-07-31.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
