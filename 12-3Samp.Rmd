# Random sampling in R
International Standard On Auditing - 530 defines^[[https://www.ifac.org/system/files/downloads/a027-2010-iaasb-handbook-isa-530.pdf](https://www.ifac.org/system/files/downloads/a027-2010-iaasb-handbook-isa-530.pdf)] audit sampling as _the application of audit procedures to less than 100% of items within a population of audit relevance such that all sampling units have a chance of selection in order to provide the auditor with a reasonable basis on which to draw conclusions about the entire population._  Statistical sampling is further defines as _an approach to sampling having two characteristics - random selection of samples, and the use of probability theory to evaluate sample results, including measurement of sampling risk._

Appendix 4 of ISA 53 further prescribes different statistical methods of sample selection.  We will discuss here each type of sampling methodology used to sample records for audit.

**Prerequisites**

Load `tidyverse`
```{r message=FALSE}
library(tidyverse)
```

## Simple Random Sampling (With and without replacement)
In this method, records are selected completely at random, by generating random numbers e.g. using random number tables, etc. Refer figure \@ref(fig:simple) for illustration. We can replicate the method of random number generation in R.  Even the method of random number generation can be reproducible, by fixing the random number seed.  Mainly two functions will be used here `sample()`\index{sample() function} and `set.seed()`\index{set.seed() function} already discussed in section \@ref(prob). Since `sample()` function takes a vector as input and gives vector as output again, we can make use of `dplyr::slice_sample()` function, discussed in section \@ref(prob), which operates on data frames instead.


```{r simple, echo=FALSE, fig.cap="Illustration of Simple Random Sampling", fig.align='center', fig.show='hold', out.width="99%"}
knitr::include_graphics("images/simple.png")
```

Let's see this sampling on `iris` data.  Suppose we have to select a sample of `n=12` records, without replacement-
```
dat <- iris # input data
# set the seed
set.seed(123)
# sample n records
dat %>% 
  slice_sample(n = 12, replace = FALSE)
```
```{r echo=FALSE}
dat <- iris
set.seed(123)
knitr::kable(
  slice_sample(dat, n=12, replace = FALSE)
)
```

The syntax is simple.  In the first step we have fixed the random number seed for reproducibility. Using `slice_sample()` we have selected `n=12` records without replacement (`replace = FALSE`).  

> If sample size is based on some proportion, we have to use `prop = .10` (say 10%) instead of `n` argument. Moreover, if sampling is with replacement, we have to use `replace = TRUE`.

## Systematic random sampling {#srs}
ISA 530 defines this sampling approach as _'Systematic selection, in which the number of sampling units in the population is divided by the sample size to give a sampling interval, for example 50, and having determined a starting point within the first 50, each 50th sampling unit thereafter is selected. Although the starting point may be determined haphazardly, the sample is more likely to be truly random if it is determined by use of a computerized random number generator or random number tables. When using systematic selection, the auditor would need to determine that sampling units within the population are not structured in such a way that the sampling interval corresponds with a particular pattern in the population.'_ Refer figure \@ref(fig:systematic) for illustration.

```{r systematic, echo=FALSE, fig.cap="Illustration of Systematic Random Sampling", fig.align='center', fig.show='hold', out.width="99%"}
knitr::include_graphics("images/systematic.png")
```
We can replicate this approach again following two steps-

__Step-1:__ Select `n` as the sample size.  Then generate a maximum starting point say `s` by dividing number of rows in the data by `n`. Thereafter we have to choose a starting point from `1:s`.  We can use sample function here.  Let's say this starting number is `s1`.  Then we have to generate an arithmetic sequence, say `rand_seq` starting from `s1` and increasing every `s` steps thereafter with total `n` terms.

__Step-2:__ In the next step we will shuffle the data by using `slice_sample` and select a sample using function `filter`.

The methodology is replicated as 
```
set.seed(123)
n <- 15 # sample size
s <- floor(nrow(dat)/n)
s1 <- sample(1:s, 1, replace = FALSE)
rand_seq <- seq(s1, by = s, length.out = n)
dat %>% 
  slice_sample(prop = 1) %>% 
  filter(row_number() %in% rand_seq)
  
```
```{r echo=FALSE}
set.seed(123)
n <- 15 # sample size
s <- floor(nrow(dat)/n)
s1 <- sample(1:s, 1, replace = FALSE)
rand_seq <- seq(s1, by = s, length.out = n)
knitr::kable(
  dat %>% 
  slice_sample(prop = 1) %>% 
  filter(row_number() %in% rand_seq)
)
```


## Probability Proportionate to size (with or without replacement) a.k.a monetary unit sampling

This sampling approach is defined in ISA-530 as _"a type of value-weighted selection in which sample size, selection and evaluation results in a conclusion in monetary amounts."_ 

Our methodology is not much difference from methodology adopted in section \@ref(srs) except that we will make use of `weight_by = ` argument now.

Let's use `state.x77` data that comes with base R.  Since the data is in matrix format, let's first convert it data frame using `as.data.frame()` first.  
```{r}
dat <- as.data.frame(state.x77)
```
Other steps are simple.  
```
set.seed(123)
dat %>% 
  slice_sample(n=12, weight_by = Population)
```
```{r echo=FALSE}
set.seed(123)
knitr::kable(
  dat %>% 
    slice_sample(n=12, weight_by = Population)
)
```

## Stratified random sampling 
Stratification is defined in ISA-530 as _the process of dividing a population into sub-populations, each of which is a group of sampling units which have similar characteristics (often monetary value)._ Thus, stratified random sampling may imply any of the afore-mentioned sampling techniques applied to individual strata instead of whole population.  Refer figure \@ref(fig:strata) for illustration.

```{r strata, echo=FALSE, fig.cap="Illustration of Stratified Random Sampling", fig.align='center', fig.show='hold', out.width="99%"}
knitr::include_graphics("images/stratified.png")
```

The function `dplyr::group_by()` will be used here for stratification.  Thereafter we can proceed for sampling described as above.

Example Data: - Let's include region in `state.x77` data using `dplyr::bind_cols`.
```{r}
dat <- bind_cols(
  as.data.frame(state.x77),
  as.data.frame(state.region)
)
```
Let's see first 6 rows of this data
```{r echo=FALSE}
knitr::kable(
  dat %>% head()
)
```
We can check a summary of number of States per region
```{r}
dat %>% 
  tibble::rownames_to_column('State') %>% # this step will not be 
                                  # used in databases without row names
  group_by(state.region) %>% 
  summarise(states = n())
```

__Case-1:__ When the sample size is constant for all strata. Say `2` records per region.
```
set.seed(123)
n <- 2
dat %>% 
  tibble::rownames_to_column('State') %>% # this step will not be used in databases without row names
  group_by(state.region) %>% 
  slice_sample(n=n) %>% 
  ungroup()
```
```{r echo=FALSE}
set.seed(123)
n <- 2
knitr::kable(
  dat %>% 
  tibble::rownames_to_column('State') %>% 
  group_by(state.region) %>% 
  slice_sample(n=n) %>% 
    ungroup()
)
```

__Case-2:__ When the sample size or proportion is different among strata.
This time let us assume that column for _stratum_ is not directly available in the data.  
- Say, 20% of States having Population upto `1000`; 
- 30% of States having population greater than `1000` but upto `5000` and finally; 
- 50% of states having population more than `5000` have to be sampled.

In this scenario, our strategy would be use `purrr::map2_dfr()` function after splitting the data with `group_split()` function.  

Syntax would be
```
# define proportions
props <- c(0.2, 0.3, 0.5)

# set seed
set.seed(123)

# take data
dat %>% 
  # reduntant step where data has no column names
  tibble::rownames_to_column('State') %>%
  # create column according to stratums
  mutate(stratum = cut(Population, c(0, 1000, 5000, max(Population)),
                      labels = c("Low", "Mid", "High"))) %>% 
  # split data into groups
  group_split(stratum) %>% 
  # sample in each group
  map2_dfr(props,
           .f = function(d, w) slice_sample(d, prop = w))
```
We may check the sample selected across each stratum
```{r echo=FALSE}
props <- c(0.2, 0.3, 0.5)
set.seed(123)
dat %>% 
  # reduntant step where data has no column names
  tibble::rownames_to_column('State') %>%
  # create column according to stratums
  mutate(stratum = cut(Population, c(0, 1000, 5000, max(Population)),
                       labels = c("Low", "Mid", "High"))) %>% 
  group_by(stratum) %>% 
  mutate(count = n()) %>% 
  ungroup() %>% 
  # split data into groups
  group_split(stratum) %>% 
  # sample in each group
  map2_dfr(props,
           .f = function(d, w) slice_sample(d, prop = w)) -> dat2
dat2 %>% 
  group_by(stratum) %>% 
  summarise(Total = mean(count),
            Selected = n()) -> dat2

knitr::kable(dat2)
```

## Cluster sampling
ISA 530 does not explicitly define cluster sampling.  Actually this sampling is sampling of strata and we can apply above mentioned techniques easily to sample clusters.  E.g. in the sample data above, we can sample say, 2 clusters (or regions).  

Thus, our strategy would be first to sample groups from unique available values and thereafter filter all the records.
```{r}
# set the seed
set.seed(123)
# sample clusters
clusters <- sample(
  unique(dat$state.region),
  size = 2
)
# filter all records in above clusters
clust_samp <- dat %>% 
  filter(state.region %in% clusters)
# check number of records
clust_samp$state.region %>% table()
```
