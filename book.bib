

@Book{xie2015,
  title = {Dynamic Documents with {R} and knitr},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2015},
  edition = {2nd},
  note = {ISBN 978-1498716963},
  url = {http://yihui.name/knitr/},
}

@InCollection{knitr2014,
  booktitle = {Implementing Reproducible Computational
    Research},
  editor = {Victoria Stodden and Friedrich Leisch and Roger
    D. Peng},
  title = {knitr: A Comprehensive Tool for Reproducible
    Research in {R}},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  year = {2014},
  note = {ISBN 978-1466561595},
  url = {http://www.crcpress.com/product/isbn/
    9781466561595},
}

@article{10.2307/1390807,
 ISSN = {10618600},
 URL = {http://www.jstor.org/stable/1390807},
 abstract = {In this article we discuss our experience designing and implementing a statistical computing language. In developing this new language, we sought to combine what we felt were useful features from two existing computer languages. We feel that the new language provides advantages in the areas of portability, computational efficiency, memory management, and scoping.},
 author = {Ross Ihaka and Robert Gentleman},
 journal = {Journal of Computational and Graphical Statistics},
 number = {3},
 pages = {299--314},
 publisher = {[American Statistical Association, Taylor and Francis, Ltd., Institute of Mathematical Statistics, Interface Foundation of America]},
 title = {R: A Language for Data Analysis and Graphics},
 urldate = {2022-05-27},
 volume = {5},
 year = {1996}
}


@article{JSSv059i10,
 title={Tidy Data},
 volume={59},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v059i10},
 doi={10.18637/jss.v059.i10},
 abstract={A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
 number={10},
 journal={Journal of Statistical Software},
 author={Wickham, Hadley},
 year={2014},
 pages={1–23}
}


@Article{layered-grammar,
  author = {Hadley Wickham},
  doi = {10.1198/jcgs.2009.07098},
  journal = {Journal of Computational and Graphical Statistics},
  number = {1},
  pages = {3–28},
  selected = {TRUE},
  title = {A layered grammar of graphics},
  volume = {19},
  year = {2010},
  bdsk-url-1 = {http://dx.doi.org/10.1198/jcgs.2009.07098},
}

@article{JSSv021i12,
 title={Reshaping Data with the reshape Package},
 volume={21},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v021i12},
 doi={10.18637/jss.v021.i12},
 abstract={This paper presents the reshape package for R, which provides a common framework for many types of data reshaping and aggregation. It uses a paradigm of ’melting’ and ’casting’, where the data are ’melted’ into a form which distinguishes measured and identifying variables, and then ’cast’ into a new shape, whether it be a data frame, list, or high dimensional array. The paper includes an introduction to the conceptual framework, practical advice for melting and casting, and a case study.},
 number={12},
 journal={Journal of Statistical Software},
 author={Wickham, Hadley},
 year={2007},
 pages={1–20}
}

@article{JSSv040i03,
 title={Dates and Times Made Easy with lubridate},
 volume={40},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v040i03},
 doi={10.18637/jss.v040.i03},
 abstract={This paper presents the lubridate package for R, which facilitates working with dates and times. Date-times create various technical problems for the data analyst. The paper highlights these problems and offers practical advice on how to solve them using &amp;lt;b&amp;gt;lubridate&amp;lt;/b&amp;gt;. The paper also introduces a conceptual framework for arithmetic with date-times in R.},
 number={3},
 journal={Journal of Statistical Software},
 author={Grolemund, Garrett and Wickham, Hadley},
 year={2011},
 pages={1–25}
}

@Manual{r-tibble,
    title = {tibble: Simple Data Frames},
    author = {Kirill Müller and Hadley Wickham},
    year = {2022},
    note = {R package version 3.1.7},
    url = {https://CRAN.R-project.org/package=tibble},
  }

@Manual{r-stringi,
    title = {stringi: Fast and portable character string processing in R},
    author = {Marek Gagolewski},
    year = {2021},
    note = {R package version 1.7.6},
    url = {https://stringi.gagolewski.com/},
  }


@article{newcomb,
 ISSN = {00029327, 10806377},
 URL = {http://www.jstor.org/stable/2369148},
 author = {Simon Newcomb},
 journal = {American Journal of Mathematics},
 number = {1},
 pages = {39--40},
 publisher = {Johns Hopkins University Press},
 title = {Note on the Frequency of Use of the Different Digits in Natural Numbers},
 urldate = {2022-06-15},
 volume = {4},
 year = {1881}
}

@article{durtschi,
author = {Durtschi, Cindy and Hillison, William and Pacini, Carl},
year = {2004},
month = {01},
pages = {},
title = {The Effective Use of Benford's Law to Assist in Detecting Fraud in Accounting Data},
volume = {5},
journal = {J. Forensic Account}
}


@article{frank_ben,
 ISSN = {0003049X},
 URL = {http://www.jstor.org/stable/984802},
 abstract = {It has been observed that the first pages of a table of common logarithms show more wear than do the last pages, indicating that more used numbers begin with the digit 1 than with the digit 9. A compilation of some 20,000 first digits taken from widely divergent sources shows that there is a logarithmic distribution of first digits when the numbers are composed of four or more digits. An analysis of the numbers from different sources shows that the numbers taken from unrelated subjects, such as a group of newspaper items, show a much better agreement with a logarithmic distribution than do numbers from mathematical tabulations or other formal data. There is here the peculiar fact that numbers that individually are without relationship are, when considered in large groups, in good agreement with a distribution law-hence the name "Anomalous Numbers." A further analysis of the data shows a strong tendency for bodies of numerical data to fall into geometric series. If the series is made up of numbers containing three or more digits the first digits form a logarithmic series. If the numbers contain only single digits the geometric relation still holds but the simple logarithmic relation no longer applies. An equation is given showing the frequencies of first digits in the different orders of numbers 1 to 10, 10 to 100, etc. The equation also gives the frequency of digits in the second, third... place of a multi-digit number, and it is shown that the same law applies to reciprocals. There are many instances showing that the geometric series, or the logarithmic law, has long been recognized as a common phenomenon in factual literature and in the ordinary affairs of life. The wire gauge and drill gauge of the mechanic, the magnitude scale of the astronomer and the sensory response curves of the psychologist are all particular examples of a relationship that seems to extend to all human affairs. The Law of Anomalous Numbers is thus a general probability law of widespread application.},
 author = {Frank Benford},
 journal = {Proceedings of the American Philosophical Society},
 number = {4},
 pages = {551--572},
 publisher = {American Philosophical Society},
 title = {The Law of Anomalous Numbers},
 urldate = {2022-06-15},
 volume = {78},
 year = {1938}
}

@article{pinkham,
  author = {Roger S. Pinkham},
  title = {{On the Distribution of First Significant Digits}},
  volume = {32},
  journal = {The Annals of Mathematical Statistics},
  number = {4},
  publisher = {Institute of Mathematical Statistics},
  pages = {1223 -- 1230},
  year = {1961},
  doi = {10.1214/aoms/1177704862},
  URL = {https://doi.org/10.1214/aoms/1177704862}
}

@article{t_hill,
 ISSN = {00029890, 19300972},
 URL = {http://www.jstor.org/stable/2974952},
 author = {Theodore P. Hill},
 journal = {The American Mathematical Monthly},
 number = {4},
 pages = {322--327},
 publisher = {Mathematical Association of America},
 title = {The Significant-Digit Phenomenon},
 urldate = {2022-06-15},
 volume = {102},
 year = {1995}
}

@article{articlesec,
  author = {Nigrini, Mark and Miller, Steven},
  year = {2009},
  month = {11},
  pages = {},
  title = {Data Diagnostics Using Second-Order Tests of Benford's Law},
  volume = {28},
  journal = {Auditing a Journal of Practice and Theory  AUDITING J PRACT THEOR},
  doi = {10.2308/aud.2009.28.2.305}
}


@Book{nigrinifraud,
  title = {Benford's Law Applications for Forensic Accounting, Auditing and Fraud Detection},
  author = {Mark J Nigrini},
  publisher = {John Wiley and Sons, Ltd},
  year = {2012},
  edition = {1st},
  note = {ISBN 978-1-118-15285-0},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119203094.ch5},
}


@inbook{dea,
author = {Cooper, William and Seiford, Lawrence and Zhu, Joe},
year = {2011},
month = {08},
pages = {1-39},
title = {Data Envelopment Analysis: History, Models, and Interpretations},
journal = {Handbook on Data Envelopment Analysis},
doi = {10.1007/978-1-4419-6151-8_1}
}


@article{mcke,
author = {Gardner, Everette S. and Mckenzie, Ed.},
title = {Forecasting Trends in Time Series},
journal = {Management Science},
volume = {31},
number = {10},
pages = {1237-1246},
year = {1985},
doi = {10.1287/mnsc.31.10.1237},

URL = {

        https://doi.org/10.1287/mnsc.31.10.1237



},
eprint = {

        https://doi.org/10.1287/mnsc.31.10.1237



}
,
    abstract = { Most time series methods assume that any trend will continue unabated, regardless of the forecast lead time. But recent empirical findings suggest that forecast accuracy can be improved by either damping or ignoring altogether trends which have a low probability of persistence. This paper develops an exponential smoothing model designed to damp erratic trends. The model is tested using the sample of 1,001 time series first analyzed by Makridakis et al. Compared to smoothing models based on a linear trend, the model improves forecast accuracy, particularly at long leadtimes. The model also compares favorably to sophisticated time series models noted for good long-range performance, such as those of Lewandowski and Parzen. }
}


@article{article2007,
author = {Nigrini, Mark and Miller, Steven},
year = {2007},
month = {09},
pages = {469-490},
title = {Benford’s Law Applied to Hydrology Data—Results and Relevance to Other Geophysical Data},
volume = {39},
journal = {Mathematical Geology},
doi = {10.1007/s11004-007-9109-5}
}


@article{article2009,
author = {Nigrini, Mark and Miller, Steven},
year = {2009},
month = {11},
pages = {},
title = {Data Diagnostics Using Second-Order Tests of Benford's Law},
volume = {28},
journal = {Auditing-a Journal of Practice and Theory - AUDITING-J PRACT THEOR},
doi = {10.2308/aud.2009.28.2.305}
}
